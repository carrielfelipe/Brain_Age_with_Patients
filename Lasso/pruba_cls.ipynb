{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=  'C:/Users/felipe/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/'\n",
    "#import sys\n",
    "#sys.path.append(path) \n",
    "path_=  'C:/Users/felipe/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/Brain_Model/'\n",
    "import sys\n",
    "sys.path.append(path_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import shap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from nilearn import plotting\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "class BaseClassifier:\n",
    "    def __init__(self,save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None, model_params_search=None,fit_params_train=None, models_params_train=None, name_model=None):             \n",
    "       \n",
    "        self.scaler = scaler if scaler is not None else StandardScaler()\n",
    "        self.params = params if params is not None else {}\n",
    "        self.params_space = params_space if params_space is not None else {}\n",
    "        self.fit_params_search = fit_params_search if fit_params_search is not None else {}\n",
    "        self.model_params_search = model_params_search if model_params_search is not None else {}\n",
    "        self.fit_params_train = fit_params_train if fit_params_train is not None else {}\n",
    "        self.model_params_train = models_params_train if models_params_train is not None else {}\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.model_ml = None\n",
    "        self.name_model = name_model\n",
    "        self.model = None\n",
    "        self.opt_model = None\n",
    "        self.explainer = None\n",
    "\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "        self.x_train_kf = None\n",
    "        self.y_train_kf= None\n",
    "\n",
    "        self.early_stopping_rounds = 10\n",
    "\n",
    "        self.residual_model = None\n",
    "\n",
    "\n",
    "    def search_best_model(self,  X=None, y=None, param_space_=None, n_iter_=10, n_jobs_=-1, scoring_metric='accuracy', type_model=1):\n",
    "       \n",
    "        if X is None:\n",
    "            X = self.X_train\n",
    "        if y is None:\n",
    "            y = self.y_train\n",
    "\n",
    "        if param_space_ is None:\n",
    "            param_space = self.params_space\n",
    "        else:\n",
    "            param_space = param_space_\n",
    "\n",
    "        n_splits = 10\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=126)       \n",
    "        \n",
    "        if type_model == 1:\n",
    "            model = self.model_ml(**self.model_params_search)\n",
    "        if type_model == 2:\n",
    "            model = self.model_ml \n",
    "\n",
    "        opt_model = BayesSearchCV(\n",
    "            estimator=model,\n",
    "            search_spaces=param_space,\n",
    "            #fit_params=self.fit_param,\n",
    "            cv=kf,\n",
    "            n_iter=n_iter_,\n",
    "            #scoring=scoring_metric,\n",
    "            n_jobs=n_jobs_,\n",
    "            random_state=42,\n",
    "            verbose=1\n",
    "        )                \n",
    "        opt_model.fit(X, y, **self.fit_params_search)\n",
    "        best_params_return = dict(opt_model.best_params_)  \n",
    "\n",
    "        return opt_model, best_params_return\n",
    "    \n",
    "\n",
    "    def trainer(self, df, n_splits=10, n_iterations=20, params_=None, type_model=1, scaler=2, early_stop=False):\n",
    "        \n",
    "        if params_ is None:\n",
    "            params = self.params\n",
    "        else:\n",
    "            params = params_\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Preparar el dataframe de controles\n",
    "        X = df.iloc[:, :-2]  # Features\n",
    "        y = df.iloc[:, -2]   # Labels (Age)\n",
    "        ID = df.iloc[:, -1]  # IDs\n",
    "        results_per_fold_train = []\n",
    "        results_per_fold_test = []\n",
    "                \n",
    "        results_labels_df_train = pd.DataFrame(columns=['y_labels','y_pred','y_prob', 'ID-unique-2'])\n",
    "        results_labels_df_test = pd.DataFrame(columns=['y_labels', 'y_pred','y_prob', 'ID-unique-2'])\n",
    "\n",
    "        # Inicializar resultados\n",
    "        results = {'model': [],\n",
    "                    'mean_X_train_kf':[],\n",
    "                    'std_X_train_kf':[],\n",
    "                    'min_X_train_kf':[],\n",
    "                    'max_X_train_kf':[],\n",
    "                    'slope': [],\n",
    "                    'intercept': [],\n",
    "                    }\n",
    "        \n",
    "        # Bucle de iteraciones\n",
    "        for i in range(n_iterations):\n",
    "            # Crear validación cruzada para CN\n",
    "            kf_CN = KFold(n_splits=n_splits, shuffle=True, random_state=i)\n",
    "            kf_splits = list(kf_CN.split(X, y))\n",
    "            \n",
    "            for fold in range(n_splits):\n",
    "                # Obtener índices de entrenamiento y prueba para CN\n",
    "                train_index, test_index = kf_splits[fold]\n",
    "                X_train_kf, X_test_kf_CN = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train_kf, y_test_kf_CN = y.iloc[train_index], y.iloc[test_index]\n",
    "                id_train_kf = ID.iloc[train_index]\n",
    "                id_test_kf = ID.iloc[test_index]\n",
    "\n",
    "                mean_X_train_kf = X_train_kf.mean()\n",
    "                std_X_train_kf = X_train_kf.std()\n",
    "                min_X_train_kf = X_train_kf.min()\n",
    "                max_X_train_kf = X_train_kf.max()\n",
    "\n",
    "                # Escalar los datos de acuerdo con el parámetro scaler\n",
    "                if scaler == 1:\n",
    "                    # No escalar\n",
    "                    X_train_kf_scaled = X_train_kf\n",
    "                    X_test_kf_scaled = X_test_kf_CN\n",
    "                elif scaler == 2:\n",
    "                    # Z-score scaling                    \n",
    "                    X_train_kf_scaled = (X_train_kf - mean_X_train_kf) / std_X_train_kf\n",
    "                    X_test_kf_scaled = (X_test_kf_CN - mean_X_train_kf) / std_X_train_kf\n",
    "                elif scaler == 3:\n",
    "                    # MinMax scaling (manual)                    \n",
    "                    X_train_kf_scaled = (X_train_kf - min_X_train_kf) / (max_X_train_kf - min_X_train_kf)\n",
    "                    X_test_kf_scaled = (X_test_kf_CN - min_X_train_kf) / (max_X_train_kf - min_X_train_kf)\n",
    "\n",
    "                self.x_train_kf = X_train_kf_scaled\n",
    "                self.y_train_kf=y_train_kf\n",
    "\n",
    "\n",
    "                # Entrenar el modelo con CN\n",
    "                if type_model == 1:\n",
    "                    model = self.model_ml(**params, **self.model_params_train)\n",
    "                if type_model == 2:\n",
    "                    model = self.model_ml\n",
    "\n",
    "                if early_stop:\n",
    "                    self.fit_params_train = {\n",
    "                    \"early_stopping_rounds\": self.early_stopping_rounds,\n",
    "                    \"eval_set\": \"mae\",\n",
    "                    \"eval_set\": self.get_eval_set(),\n",
    "                    \"verbose\": False\n",
    "                    }\n",
    "\n",
    "                    \n",
    "                model.fit(X_train_kf_scaled, y_train_kf,**self.fit_params_train)\n",
    "\n",
    "                y_pred_CN_train = model.predict(X_train_kf_scaled)\n",
    "                y_prob_CN_train = model.predict_proba(X_train_kf_scaled)[:, 1]\n",
    "\n",
    "                # Hacer predicciones para el conjunto de prueba de CN\n",
    "                y_pred_CN_test = model.predict(X_test_kf_scaled)\n",
    "                y_prob_CN_test = model.predict_proba(X_test_kf_scaled)[:, 1]\n",
    "                \n",
    "                # Guardar resultados de CN \n",
    "                temp_CN_df_test = pd.DataFrame({\n",
    "                    'y_labels': y_test_kf_CN,\n",
    "                    'y_pred': y_pred_CN_test,\n",
    "                    'y_prob':y_prob_CN_test,                    \n",
    "                    'ID-unique-2': id_test_kf\n",
    "                })\n",
    "                temp_CN_df_train = pd.DataFrame({                    \n",
    "                    'y_labels': y_train_kf,\n",
    "                    'y_pred': y_pred_CN_train, \n",
    "                    'y_prob':y_prob_CN_train  ,                 \n",
    "                    'ID-unique-2': id_train_kf\n",
    "                })\n",
    "\n",
    "                results_labels_df_train = pd.concat([results_labels_df_train, temp_CN_df_train], ignore_index=True)\n",
    "                results_per_fold_train.append(temp_CN_df_train.copy())\n",
    "                results_labels_df_test = pd.concat([results_labels_df_test, temp_CN_df_test], ignore_index=True)\n",
    "                results_per_fold_test.append(temp_CN_df_test.copy())\n",
    "\n",
    "                # Procesar cada dataframe de pacientes si lista_dfs no es None\n",
    "                \n",
    "                # Guardar el modelo entrenado\n",
    "                results['model'].append(model)\n",
    "                \n",
    "                results['mean_X_train_kf'].append(mean_X_train_kf)\n",
    "                results['std_X_train_kf'].append(std_X_train_kf)\n",
    "            \n",
    "                results['min_X_train_kf'].append(min_X_train_kf)\n",
    "                results['max_X_train_kf'].append(max_X_train_kf)\n",
    "                \n",
    "                    \n",
    "\n",
    "        return results_labels_df_train, results_labels_df_test, results, results_per_fold_train,results_per_fold_test\n",
    "\n",
    "\n",
    "    def best_hyper(self, opt_model, num_best=10, num_max=400):\n",
    "        \"\"\"\n",
    "        Obtiene los mejores hiperparámetros para las mejores puntuaciones de validación cruzada dentro de los primeros num_max resultados.\n",
    "        \n",
    "        \"\"\"\n",
    "        results = opt_model.cv_results_\n",
    "        errors = results['mean_test_score'][:num_max]  # Considerar solo los primeros num_max resultados\n",
    "        best_idx = np.argsort(errors)[-num_best:]  # Obtener los índices de las mejores puntuaciones\n",
    "        best_hypers = []\n",
    "\n",
    "        for idx in best_idx:\n",
    "            hyper = {}\n",
    "            for param, value in results['params'][idx].items():\n",
    "                hyper[param] = value\n",
    "            best_hypers.append(hyper)\n",
    "\n",
    "        # Invertir el orden para que el mejor esté en el índice 0\n",
    "        best_hypers = best_hypers[::-1]\n",
    "\n",
    "        return best_hypers\n",
    "    \n",
    "    def avg_list(self, df_list):\n",
    "        results_avg = []\n",
    "        for df in df_list:            \n",
    "            df_avg = df.groupby('ID-unique-2').agg({\n",
    "                'y_labels': 'mean',\n",
    "                'y_pred': 'mean', \n",
    "                'y_prob': 'mean'               \n",
    "            }).reset_index()\n",
    "            results_avg.append(df_avg)\n",
    "        return results_avg\n",
    "    \n",
    "    def avg_list_threshold(self, df_list):\n",
    "        results_avg = []\n",
    "        for df in df_list:\n",
    "            df_avg = df.groupby('ID-unique-2').agg({\n",
    "                'y_labels': 'mean',\n",
    "                'y_pred': 'mean',\n",
    "                'y_prob': 'mean'\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Convertir el promedio de y_pred a 0 o 1 según el umbral de 0.5\n",
    "            df_avg['y_pred'] = (df_avg['y_pred'] >= 0.5).astype(int)\n",
    "            results_avg.append(df_avg)\n",
    "        return results_avg\n",
    "    \n",
    "    \n",
    "\n",
    "    def majority_vote(self, df_list):\n",
    "        results_avg = []\n",
    "        for df in df_list:\n",
    "            # Tomar la moda (valor más frecuente) para y_labels y y_pred\n",
    "            df_avg = df.groupby('ID-unique-2').agg({\n",
    "                'y_labels': lambda x: x.mode()[0],\n",
    "                'y_pred': lambda x: x.mode()[0],\n",
    "                'y_prob': lambda x: x.mode()[0]\n",
    "            }).reset_index()\n",
    "            results_avg.append(df_avg)\n",
    "        return results_avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#from base_regressor import BaseClassifier\n",
    "from Plotter import Plotter\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "class XGBoostClassifier(BaseClassifier):\n",
    "    def __init__(self, save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None, model_params_search=None, fit_params_train=None, model_params_train=None, name_model=\"Lasso\"):\n",
    "        super().__init__(save_path, scaler, params, params_space, fit_params_search, model_params_search, fit_params_train, model_params_train, name_model)\n",
    "\n",
    "        self.model_ml = xgb.XGBClassifier\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'alpha': 0.2,\n",
    "                'max_iter': 10000,\n",
    "                #'tol': 0.001\n",
    "            }\n",
    "        if params_space is None:\n",
    "            self.params_space = {\n",
    "                'objective'   : ['binary:logistic'],\n",
    "                'eval_metric' : ['logloss', 'error', 'auc', 'aucpr'],\n",
    "                'learning_rate': (0.01, 0.1, 0.2),\n",
    "                'max_depth': (3, 4, 5),\n",
    "                'subsample': (0.8, 0.9, 1.0),\n",
    "                'colsample_bytree': (0.8, 0.9, 1.0),\n",
    "                'reg_alpha': (0, 0.1, 1.0),\n",
    "                'reg_lambda': (0, 0.1, 1.0),\n",
    "                #'gamma': (0.001, 0.01, 0.1, 1, 10),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = XGBoostClassifier()\n",
    "Plotters = Plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los dataframes desde los archivos Excel\n",
    "df_CN_results_ = pd.read_excel('results/df_CN_results.xlsx')\n",
    "df_AD_results_ = pd.read_excel('results/df_AD_results.xlsx')\n",
    "df_FTD_results_ = pd.read_excel('results/df_FTD_results.xlsx')\n",
    "df_MCI_results_ = pd.read_excel('results/df_MCI_results.xlsx')\n",
    "df_PD_results_ = pd.read_excel('results/df_PD_results.xlsx')\n",
    "\n",
    "# Agregar la columna Diagnosis a cada dataframe antes de concatenar\n",
    "df_CN_results_['Diagnosis'] = 1  # CN\n",
    "df_AD_results_['Diagnosis'] = 2  # AD\n",
    "df_FTD_results_['Diagnosis'] = 2  # FTD\n",
    "df_MCI_results_['Diagnosis'] = 2  # MCI\n",
    "df_PD_results_['Diagnosis'] = 2  # PD\n",
    "\n",
    "\n",
    "\n",
    "# Combinar todos los dataframes\n",
    "df_results_combined = pd.concat([df_CN_results_, df_AD_results_, df_FTD_results_, df_MCI_results_, df_PD_results_], ignore_index=True)\n",
    "df_results_combined['ID-unique-2'] = range(len(df_results_combined))\n",
    "\n",
    "# Lista de columnas a limpiar\n",
    "columns_to_clean = ['Educ', 'Sex', 'MMSE', 'GINI']\n",
    "\n",
    "# Convertir las columnas a numérico, convirtiendo valores no numéricos a NaN\n",
    "df_results_combined[columns_to_clean] = df_results_combined[columns_to_clean].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Eliminar filas donde cualquiera de las columnas especificadas es NaN\n",
    "df_results_combined = df_results_combined.dropna(subset=columns_to_clean)\n",
    "\n",
    "# Resetear el índice después de eliminar las filas\n",
    "df_results_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "median_brain_age = df_results_combined['y_labels'].median()\n",
    "df_results_combined['brain_age_class'] = df_results_combined['y_labels'].apply(lambda x: 1 if x > median_brain_age else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID-unique</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_corrected</th>\n",
       "      <th>GAP</th>\n",
       "      <th>GAP_corrected</th>\n",
       "      <th>Country_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>HDI</th>\n",
       "      <th>GINI</th>\n",
       "      <th>ODQ</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>ID-unique-2</th>\n",
       "      <th>brain_age_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.975190</td>\n",
       "      <td>56.195626</td>\n",
       "      <td>11.975190</td>\n",
       "      <td>1.195626</td>\n",
       "      <td>CUB_123_2_sub-100035</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>98.976304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>62.0</td>\n",
       "      <td>69.369323</td>\n",
       "      <td>65.377834</td>\n",
       "      <td>7.369323</td>\n",
       "      <td>3.377834</td>\n",
       "      <td>CUB_123_1_sub-100012</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>99.691591</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.724968</td>\n",
       "      <td>69.631386</td>\n",
       "      <td>-0.275032</td>\n",
       "      <td>1.631386</td>\n",
       "      <td>CUB_62_sub-100037</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>95.638864</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>57.0</td>\n",
       "      <td>68.059997</td>\n",
       "      <td>59.231859</td>\n",
       "      <td>11.059997</td>\n",
       "      <td>2.231859</td>\n",
       "      <td>CUB_62_sub-100092</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>97.391599</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.206586</td>\n",
       "      <td>70.062372</td>\n",
       "      <td>-1.793414</td>\n",
       "      <td>1.062372</td>\n",
       "      <td>ARG_B1_sub-10002</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>41.793333</td>\n",
       "      <td>99.483527</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>35</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.433235</td>\n",
       "      <td>73.176533</td>\n",
       "      <td>-4.566765</td>\n",
       "      <td>1.176533</td>\n",
       "      <td>Chile_Tak_new_sub-100080</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.462338</td>\n",
       "      <td>2</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>36</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.155547</td>\n",
       "      <td>67.072363</td>\n",
       "      <td>1.155547</td>\n",
       "      <td>1.072363</td>\n",
       "      <td>Chile_Tak_new_sub-100083</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>98.270621</td>\n",
       "      <td>2</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>51</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.888157</td>\n",
       "      <td>73.651155</td>\n",
       "      <td>-4.111843</td>\n",
       "      <td>1.651155</td>\n",
       "      <td>Chile_Takeda_new_2_sub-100084</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.576163</td>\n",
       "      <td>2</td>\n",
       "      <td>1320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>52</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.263946</td>\n",
       "      <td>62.255509</td>\n",
       "      <td>4.263946</td>\n",
       "      <td>0.255509</td>\n",
       "      <td>Chile_Takeda_new_2_sub-100085</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.487833</td>\n",
       "      <td>2</td>\n",
       "      <td>1321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>53</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.717243</td>\n",
       "      <td>72.503415</td>\n",
       "      <td>-3.282757</td>\n",
       "      <td>1.503415</td>\n",
       "      <td>Chile_Takeda_new_2_sub-100086</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.531998</td>\n",
       "      <td>2</td>\n",
       "      <td>1322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID-unique  y_labels     y_pred  y_pred_corrected        GAP  \\\n",
       "0            27      55.0  66.975190         56.195626  11.975190   \n",
       "1            55      62.0  69.369323         65.377834   7.369323   \n",
       "2           111      68.0  67.724968         69.631386  -0.275032   \n",
       "3           161      57.0  68.059997         59.231859  11.059997   \n",
       "4           209      69.0  67.206586         70.062372  -1.793414   \n",
       "...         ...       ...        ...               ...        ...   \n",
       "1095         35      72.0  67.433235         73.176533  -4.566765   \n",
       "1096         36      66.0  67.155547         67.072363   1.155547   \n",
       "1097         51      72.0  67.888157         73.651155  -4.111843   \n",
       "1098         52      62.0  66.263946         62.255509   4.263946   \n",
       "1099         53      71.0  67.717243         72.503415  -3.282757   \n",
       "\n",
       "      GAP_corrected                     Country_ID   Age  Sex  Educ   MMSE  \\\n",
       "0          1.195626          CUB_123_2_sub-100035   55.0  2.0  13.0  30.00   \n",
       "1          3.377834          CUB_123_1_sub-100012   62.0  2.0  13.0  30.00   \n",
       "2          1.631386             CUB_62_sub-100037   68.0  2.0  10.0  30.00   \n",
       "3          2.231859             CUB_62_sub-100092   57.0  2.0  10.0  29.00   \n",
       "4          1.062372             ARG_B1_sub-10002    69.0  2.0  15.0  29.00   \n",
       "...             ...                            ...   ...  ...   ...    ...   \n",
       "1095       1.176533       Chile_Tak_new_sub-100080  72.0  1.0  15.0  29.96   \n",
       "1096       1.072363       Chile_Tak_new_sub-100083  66.0  1.0  14.0  29.17   \n",
       "1097       1.651155  Chile_Takeda_new_2_sub-100084  72.0  1.0  15.0  29.96   \n",
       "1098       0.255509  Chile_Takeda_new_2_sub-100085  62.0  1.0  13.0  32.33   \n",
       "1099       1.503415  Chile_Takeda_new_2_sub-100086  71.0  2.0  17.0  30.75   \n",
       "\n",
       "         HDI       GINI        ODQ  Diagnosis  ID-unique-2  brain_age_class  \n",
       "0     0.7578  40.700000  98.976304          1            1                0  \n",
       "1     0.7578  40.700000  99.691591          1            3                0  \n",
       "2     0.7578  40.700000  95.638864          1            5                0  \n",
       "3     0.7578  40.700000  97.391599          1            8                0  \n",
       "4     0.8510  41.793333  99.483527          1            9                0  \n",
       "...      ...        ...        ...        ...          ...              ...  \n",
       "1095     NaN  43.000000  99.462338          2         1304                1  \n",
       "1096     NaN  43.000000  98.270621          2         1305                0  \n",
       "1097     NaN  43.000000  99.576163          2         1320                1  \n",
       "1098     NaN  43.000000  99.487833          2         1321                0  \n",
       "1099     NaN  43.000000  99.531998          2         1322                1  \n",
       "\n",
       "[1100 rows x 17 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_combined['ID-unique-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_results_combined[['Sex', 'Educ', 'MMSE', 'GINI', 'Diagnosis']]\n",
    "y = df_results_combined['brain_age_class']\n",
    "id = df_results_combined['ID-unique-2']\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "df_concatenado = pd.concat([X, y, id], axis=1, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df_concatenado, test_size=0.5, random_state=42, stratify=df_concatenado['Diagnosis']\n",
    ")\n",
    "\n",
    "# Combinar nuevamente train y test para obtener el dataset completo desordenado\n",
    "df_desordenado = pd.concat([df_train, df_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desordenado = df_desordenado[['Sex', 'Educ', 'MMSE', 'GINI', 'Diagnosis']]\n",
    "y_desordenado= df_desordenado['brain_age_class']\n",
    "id_desordenado = df_desordenado['ID-unique-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenado_desordenado = pd.concat([X_desordenado, y_desordenado, id_desordenado], axis=1, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>GINI</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>brain_age_class</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>52.608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.22</td>\n",
       "      <td>45.300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>54.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>54.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>51.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>43.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>52.608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>51.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>52.700</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.22</td>\n",
       "      <td>41.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Educ   MMSE    GINI  Diagnosis  brain_age_class  ID-unique-2\n",
       "0     2.0  11.0  26.00  52.608          1                1          320\n",
       "1     2.0  12.0  25.22  45.300          2                0          884\n",
       "2     2.0  10.0  27.00  54.800          2                1         1133\n",
       "3     1.0   8.0  26.00  54.800          2                1          744\n",
       "4     2.0  11.0  29.00  51.500          1                0          581\n",
       "...   ...   ...    ...     ...        ...              ...          ...\n",
       "1095  2.0  11.0  25.00  43.500          2                1          938\n",
       "1096  2.0   4.0  25.00  52.608          1                1          332\n",
       "1097  2.0  19.0  28.00  51.500          1                0          533\n",
       "1098  2.0  11.0  15.00  52.700          2                1          762\n",
       "1099  2.0  18.0  24.22  41.800          2                1          681\n",
       "\n",
       "[1100 rows x 7 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado_desordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "opt_model_cls, best_params_cls =model_cls.search_best_model(X=X_desordenado, y=y_desordenado, n_iter_=10, scoring_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'eval_metric': 'aucpr',\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 4,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.1,\n",
       " 'reg_lambda': 0,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 4,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 1.0},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 3,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.8,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 3,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'auc',\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 3,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 1.0},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'logloss',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 1.0,\n",
       "  'subsample': 1.0},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'error',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 1.0,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'auc',\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 4,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 0.9}]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_cls_ = model_cls.best_hyper(num_best=10, opt_model=opt_model_cls, num_max=50)\n",
    "best_params_cls_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>GINI</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>brain_age_class</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>41.793333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.17</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.33</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.75</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Educ   MMSE       GINI  Diagnosis  brain_age_class  ID-unique-2\n",
       "0     2.0  13.0  30.00  40.700000          1                0            1\n",
       "1     2.0  13.0  30.00  40.700000          1                0            3\n",
       "2     2.0  10.0  30.00  40.700000          1                0            5\n",
       "3     2.0  10.0  29.00  40.700000          1                0            8\n",
       "4     2.0  15.0  29.00  41.793333          1                0            9\n",
       "...   ...   ...    ...        ...        ...              ...          ...\n",
       "1095  1.0  15.0  29.96  43.000000          2                1         1304\n",
       "1096  1.0  14.0  29.17  43.000000          2                0         1305\n",
       "1097  1.0  15.0  29.96  43.000000          2                1         1320\n",
       "1098  1.0  13.0  32.33  43.000000          2                0         1321\n",
       "1099  2.0  17.0  30.75  43.000000          2                1         1322\n",
       "\n",
       "[1100 rows x 7 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felipe\\AppData\\Local\\Temp\\ipykernel_26668\\2485658785.py:197: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_labels_df_train = pd.concat([results_labels_df_train, temp_CN_df_train], ignore_index=True)\n",
      "C:\\Users\\felipe\\AppData\\Local\\Temp\\ipykernel_26668\\2485658785.py:199: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_labels_df_test = pd.concat([results_labels_df_test, temp_CN_df_test], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_labels_df_train, results_labels_df_test,  results_model, results_per_fold_train, results_per_fold_test = model_cls.trainer(df=df_concatenado_desordenado, n_splits=10, n_iterations=20, params_=best_params_cls_[0], scaler=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_test.to_excel('results/df_prueba___.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_labels</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643350</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289121</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361237</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385269</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512546</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411784</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447585</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345880</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654260</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791159</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_labels y_pred    y_prob ID-unique-2\n",
       "0            0      1  0.643350         884\n",
       "1            0      0  0.289121        1147\n",
       "2            1      0  0.361237         249\n",
       "3            0      0  0.385269          20\n",
       "4            0      1  0.512546         835\n",
       "...        ...    ...       ...         ...\n",
       "21995        1      0  0.411784        1003\n",
       "21996        0      0  0.447585        1283\n",
       "21997        0      0  0.345880         275\n",
       "21998        1      1  0.654260         908\n",
       "21999        1      1  0.791159         778\n",
       "\n",
       "[22000 rows x 4 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_labels_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_total = [results_labels_df_test]\n",
    "results_avg_list = model_cls.avg_list(results_labels_df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID-unique-2</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID-unique-2 y_labels y_pred    y_prob\n",
       "0               1      0.0    0.0  0.387503\n",
       "1               3      0.0    0.0  0.389980\n",
       "2               5      0.0    0.0  0.388100\n",
       "3               8      0.0    0.0  0.392020\n",
       "4               9      0.0    0.0  0.385906\n",
       "...           ...      ...    ...       ...\n",
       "1095         1304      1.0    0.0  0.446632\n",
       "1096         1305      0.0    0.0  0.445375\n",
       "1097         1320      1.0    0.0  0.446678\n",
       "1098         1321      0.0    0.0  0.428901\n",
       "1099         1322      1.0    0.0  0.412228\n",
       "\n",
       "[1100 rows x 4 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_avg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      y_labels y_pred ID-unique-2\n",
       " 0            0      1         884\n",
       " 1            0      0        1147\n",
       " 2            1      0         249\n",
       " 3            0      0          20\n",
       " 4            0      1         835\n",
       " ...        ...    ...         ...\n",
       " 21995        1      0        1003\n",
       " 21996        0      0        1283\n",
       " 21997        0      0         275\n",
       " 21998        1      1         908\n",
       " 21999        1      1         778\n",
       " \n",
       " [22000 rows x 3 columns]]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_labels_df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID-unique-2 y_labels  y_pred    y_prob\n",
      "0               1      0.0       0  0.387503\n",
      "1               3      0.0       0  0.389980\n",
      "2               5      0.0       0  0.388100\n",
      "3               8      0.0       0  0.392020\n",
      "4               9      0.0       0  0.385906\n",
      "...           ...      ...     ...       ...\n",
      "1095         1304      1.0       0  0.446632\n",
      "1096         1305      0.0       0  0.445375\n",
      "1097         1320      1.0       0  0.446678\n",
      "1098         1321      0.0       0  0.428901\n",
      "1099         1322      1.0       0  0.412228\n",
      "\n",
      "[1100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "results_avg_list = model_cls.avg_list_threshold(results_labels_df_total)\n",
    "print(results_avg_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID-unique-2  y_labels  y_pred    y_prob\n",
      "0               1         0       0  0.377585\n",
      "1               3         0       0  0.380182\n",
      "2               5         0       0  0.367036\n",
      "3               8         0       0  0.379105\n",
      "4               9         0       0  0.371979\n",
      "...           ...       ...     ...       ...\n",
      "1095         1304         1       0  0.429422\n",
      "1096         1305         0       0  0.425091\n",
      "1097         1320         1       0  0.431485\n",
      "1098         1321         0       0  0.407550\n",
      "1099         1322         1       0  0.385063\n",
      "\n",
      "[1100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "results_avg_list = model_cls.majority_vote(results_labels_df_total)\n",
    "print(results_avg_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_avg_list[0].to_excel('results/df_prueba_ttttest.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.387503\n",
       "1       0.389980\n",
       "2       0.388100\n",
       "3       0.392020\n",
       "4       0.385906\n",
       "          ...   \n",
       "1095    0.446632\n",
       "1096    0.445375\n",
       "1097    0.446678\n",
       "1098    0.428901\n",
       "1099    0.412228\n",
       "Name: y_prob, Length: 1100, dtype: float32"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_avg_list[0]['y_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# Suponiendo que `y_prob` es una probabilidad predicha; aquí se usa una probabilidad de ejemplo.\n",
    "y_true = results_avg_list[0]['y_labels']\n",
    "y_pred = results_avg_list[0]['y_pred']\n",
    "y_prob = results_avg_list[0]['y_prob'] # Reemplazar con las probabilidades reales\n",
    "\n",
    "# Definir la función de métricas de clasificación\n",
    "def clf_metrics(y_true, y_pred, y_prob):\n",
    "    # ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    \n",
    "    # Otras métricas de clasificación\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        \"AUC\": auc_value,\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr,\n",
    "        \"Thresholds\": thresholds,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"Precision\": precision,\n",
    "        \"Confusion Matrix\": cm\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.387503\n",
       "1       0.389980\n",
       "2       0.388100\n",
       "3       0.392020\n",
       "4       0.385906\n",
       "          ...   \n",
       "1095    0.446632\n",
       "1096    0.445375\n",
       "1097    0.446678\n",
       "1098    0.428901\n",
       "1099    0.412228\n",
       "Name: y_prob, Length: 1100, dtype: float32"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.7599834491890104,\n",
       " 'FPR': array([0.        , 0.00175439, 0.00175439, 0.00350877, 0.00350877,\n",
       "        0.00526316, 0.00526316, 0.00701754, 0.00701754, 0.01754386,\n",
       "        0.01754386, 0.02280702, 0.02280702, 0.0245614 , 0.0245614 ,\n",
       "        0.02631579, 0.02631579, 0.02807018, 0.02807018, 0.03157895,\n",
       "        0.03157895, 0.03333333, 0.03333333, 0.03684211, 0.03684211,\n",
       "        0.04035088, 0.04035088, 0.04561404, 0.04561404, 0.04736842,\n",
       "        0.04736842, 0.04912281, 0.04912281, 0.05087719, 0.05087719,\n",
       "        0.05263158, 0.05263158, 0.06140351, 0.06140351, 0.06315789,\n",
       "        0.06315789, 0.06491228, 0.06491228, 0.06842105, 0.06842105,\n",
       "        0.07017544, 0.07017544, 0.07192982, 0.07192982, 0.07368421,\n",
       "        0.07368421, 0.0754386 , 0.0754386 , 0.07719298, 0.07719298,\n",
       "        0.07894737, 0.07894737, 0.08070175, 0.08070175, 0.08245614,\n",
       "        0.08245614, 0.08421053, 0.08421053, 0.08596491, 0.08596491,\n",
       "        0.0877193 , 0.0877193 , 0.08947368, 0.08947368, 0.09122807,\n",
       "        0.09122807, 0.09298246, 0.09298246, 0.09473684, 0.09473684,\n",
       "        0.09649123, 0.09649123, 0.1       , 0.1       , 0.10175439,\n",
       "        0.10175439, 0.10350877, 0.10350877, 0.10701754, 0.10701754,\n",
       "        0.11403509, 0.11403509, 0.11578947, 0.11578947, 0.11754386,\n",
       "        0.11754386, 0.12105263, 0.12105263, 0.12280702, 0.12280702,\n",
       "        0.1245614 , 0.1245614 , 0.12631579, 0.12631579, 0.12807018,\n",
       "        0.12807018, 0.12982456, 0.12982456, 0.13684211, 0.13684211,\n",
       "        0.13859649, 0.13859649, 0.14035088, 0.14035088, 0.14210526,\n",
       "        0.14210526, 0.14385965, 0.14385965, 0.14561404, 0.14561404,\n",
       "        0.14736842, 0.14736842, 0.14912281, 0.14912281, 0.15438596,\n",
       "        0.15438596, 0.15789474, 0.15789474, 0.15964912, 0.15964912,\n",
       "        0.16315789, 0.16315789, 0.16491228, 0.16491228, 0.17017544,\n",
       "        0.17017544, 0.17368421, 0.17368421, 0.17719298, 0.17719298,\n",
       "        0.17894737, 0.17894737, 0.18070175, 0.18070175, 0.18947368,\n",
       "        0.18947368, 0.19122807, 0.19122807, 0.2       , 0.2       ,\n",
       "        0.20350877, 0.20350877, 0.21403509, 0.21403509, 0.22105263,\n",
       "        0.22105263, 0.2245614 , 0.2245614 , 0.22807018, 0.22807018,\n",
       "        0.23157895, 0.23157895, 0.23333333, 0.23333333, 0.23508772,\n",
       "        0.23508772, 0.23684211, 0.23684211, 0.23859649, 0.23859649,\n",
       "        0.24385965, 0.24385965, 0.25263158, 0.25263158, 0.25964912,\n",
       "        0.25964912, 0.26842105, 0.26842105, 0.27192982, 0.27192982,\n",
       "        0.27368421, 0.27368421, 0.2754386 , 0.2754386 , 0.29649123,\n",
       "        0.29649123, 0.31052632, 0.31052632, 0.3122807 , 0.3122807 ,\n",
       "        0.33684211, 0.33684211, 0.33859649, 0.33859649, 0.34210526,\n",
       "        0.34210526, 0.34561404, 0.34561404, 0.34912281, 0.34912281,\n",
       "        0.35438596, 0.35438596, 0.35789474, 0.35789474, 0.35964912,\n",
       "        0.35964912, 0.36140351, 0.36140351, 0.36315789, 0.36315789,\n",
       "        0.36491228, 0.36491228, 0.36666667, 0.36666667, 0.36842105,\n",
       "        0.36842105, 0.37192982, 0.37192982, 0.37368421, 0.37368421,\n",
       "        0.3754386 , 0.3754386 , 0.37894737, 0.37894737, 0.38245614,\n",
       "        0.38245614, 0.38596491, 0.38596491, 0.38947368, 0.38947368,\n",
       "        0.39473684, 0.39473684, 0.40701754, 0.40701754, 0.41052632,\n",
       "        0.41052632, 0.4122807 , 0.4122807 , 0.41403509, 0.41403509,\n",
       "        0.41578947, 0.41578947, 0.41929825, 0.41929825, 0.42807018,\n",
       "        0.42807018, 0.43157895, 0.43157895, 0.43333333, 0.43333333,\n",
       "        0.44035088, 0.44035088, 0.44385965, 0.44385965, 0.44561404,\n",
       "        0.44561404, 0.45087719, 0.45087719, 0.45789474, 0.45789474,\n",
       "        0.46315789, 0.46315789, 0.46491228, 0.46491228, 0.46666667,\n",
       "        0.46666667, 0.46842105, 0.46842105, 0.47368421, 0.47368421,\n",
       "        0.4754386 , 0.4754386 , 0.47719298, 0.47719298, 0.48245614,\n",
       "        0.48245614, 0.49824561, 0.49824561, 0.50350877, 0.50350877,\n",
       "        0.54210526, 0.54210526, 0.56666667, 0.56666667, 0.5754386 ,\n",
       "        0.5754386 , 0.62280702, 0.62280702, 0.6245614 , 0.6245614 ,\n",
       "        0.62982456, 0.62982456, 0.63333333, 0.63333333, 0.63508772,\n",
       "        0.63508772, 0.64035088, 0.64035088, 0.64210526, 0.64210526,\n",
       "        0.64561404, 0.64561404, 0.64736842, 0.64736842, 0.65087719,\n",
       "        0.65087719, 0.65438596, 0.65438596, 0.65964912, 0.65964912,\n",
       "        0.66842105, 0.66842105, 0.67368421, 0.67368421, 0.67719298,\n",
       "        0.67719298, 0.68421053, 0.68421053, 0.6877193 , 0.6877193 ,\n",
       "        0.68947368, 0.68947368, 0.69473684, 0.69473684, 0.69824561,\n",
       "        0.69824561, 0.7       , 0.7       , 0.74035088, 0.74035088,\n",
       "        0.74561404, 0.74561404, 0.75614035, 0.75614035, 0.75964912,\n",
       "        0.75964912, 0.76491228, 0.76491228, 0.77368421, 0.77368421,\n",
       "        0.8       , 0.8       , 0.81403509, 0.81403509, 0.81578947,\n",
       "        0.81578947, 0.83684211, 0.83684211, 0.84385965, 0.84385965,\n",
       "        0.84561404, 0.84561404, 0.84736842, 0.84736842, 0.85087719,\n",
       "        0.85087719, 0.86315789, 0.86315789, 0.87719298, 0.87719298,\n",
       "        0.88070175, 0.88070175, 0.90526316, 0.90526316, 0.90701754,\n",
       "        0.90701754, 0.94736842, 0.94736842, 0.95789474, 0.95789474,\n",
       "        0.9877193 , 0.9877193 , 1.        ]),\n",
       " 'TPR': array([0.        , 0.        , 0.00188679, 0.00188679, 0.06226415,\n",
       "        0.06226415, 0.08113208, 0.08113208, 0.1       , 0.1       ,\n",
       "        0.10188679, 0.10188679, 0.10377358, 0.10377358, 0.11132075,\n",
       "        0.11132075, 0.17924528, 0.17924528, 0.2       , 0.2       ,\n",
       "        0.20188679, 0.20188679, 0.20377358, 0.20377358, 0.20754717,\n",
       "        0.20754717, 0.21132075, 0.21132075, 0.21509434, 0.21509434,\n",
       "        0.21698113, 0.21698113, 0.22075472, 0.22075472, 0.22264151,\n",
       "        0.22264151, 0.2245283 , 0.2245283 , 0.23396226, 0.23396226,\n",
       "        0.23962264, 0.23962264, 0.25283019, 0.25283019, 0.25849057,\n",
       "        0.25849057, 0.26603774, 0.26603774, 0.26981132, 0.26981132,\n",
       "        0.27924528, 0.27924528, 0.28867925, 0.28867925, 0.29056604,\n",
       "        0.29056604, 0.29433962, 0.29433962, 0.29811321, 0.29811321,\n",
       "        0.31132075, 0.31132075, 0.39245283, 0.39245283, 0.39622642,\n",
       "        0.39622642, 0.40377358, 0.40377358, 0.40754717, 0.40754717,\n",
       "        0.41509434, 0.41509434, 0.41698113, 0.41698113, 0.42075472,\n",
       "        0.42075472, 0.42641509, 0.42641509, 0.43207547, 0.43207547,\n",
       "        0.43962264, 0.43962264, 0.45471698, 0.45471698, 0.46226415,\n",
       "        0.46226415, 0.46415094, 0.46415094, 0.4754717 , 0.4754717 ,\n",
       "        0.47924528, 0.47924528, 0.48679245, 0.48679245, 0.49245283,\n",
       "        0.49245283, 0.49811321, 0.49811321, 0.50943396, 0.50943396,\n",
       "        0.51886792, 0.51886792, 0.52264151, 0.52264151, 0.53018868,\n",
       "        0.53018868, 0.53207547, 0.53207547, 0.54339623, 0.54339623,\n",
       "        0.54716981, 0.54716981, 0.5490566 , 0.5490566 , 0.55471698,\n",
       "        0.55471698, 0.56981132, 0.56981132, 0.57358491, 0.57358491,\n",
       "        0.5754717 , 0.5754717 , 0.57735849, 0.57735849, 0.58301887,\n",
       "        0.58301887, 0.58867925, 0.58867925, 0.59433962, 0.59433962,\n",
       "        0.59622642, 0.59622642, 0.60377358, 0.60377358, 0.60566038,\n",
       "        0.60566038, 0.60943396, 0.60943396, 0.61132075, 0.61132075,\n",
       "        0.61320755, 0.61320755, 0.61698113, 0.61698113, 0.61886792,\n",
       "        0.61886792, 0.6245283 , 0.6245283 , 0.62830189, 0.62830189,\n",
       "        0.63018868, 0.63018868, 0.63962264, 0.63962264, 0.64150943,\n",
       "        0.64150943, 0.64339623, 0.64339623, 0.64528302, 0.64528302,\n",
       "        0.64716981, 0.64716981, 0.6490566 , 0.6490566 , 0.65283019,\n",
       "        0.65283019, 0.65471698, 0.65471698, 0.66037736, 0.66037736,\n",
       "        0.66226415, 0.66226415, 0.66415094, 0.66415094, 0.66792453,\n",
       "        0.66792453, 0.66981132, 0.66981132, 0.67169811, 0.67169811,\n",
       "        0.67358491, 0.67358491, 0.6754717 , 0.6754717 , 0.67924528,\n",
       "        0.67924528, 0.68113208, 0.68113208, 0.68301887, 0.68301887,\n",
       "        0.68490566, 0.68490566, 0.69245283, 0.69245283, 0.69433962,\n",
       "        0.69433962, 0.70188679, 0.70188679, 0.70566038, 0.70566038,\n",
       "        0.70943396, 0.70943396, 0.71132075, 0.71132075, 0.71886792,\n",
       "        0.71886792, 0.72075472, 0.72075472, 0.72264151, 0.72264151,\n",
       "        0.73207547, 0.73207547, 0.74528302, 0.74528302, 0.7509434 ,\n",
       "        0.7509434 , 0.75283019, 0.75283019, 0.75660377, 0.75660377,\n",
       "        0.75849057, 0.75849057, 0.76037736, 0.76037736, 0.76226415,\n",
       "        0.76226415, 0.76415094, 0.76415094, 0.76603774, 0.76603774,\n",
       "        0.76792453, 0.76792453, 0.76981132, 0.76981132, 0.77358491,\n",
       "        0.77358491, 0.7754717 , 0.7754717 , 0.77924528, 0.77924528,\n",
       "        0.78113208, 0.78113208, 0.78301887, 0.78301887, 0.79056604,\n",
       "        0.79056604, 0.8       , 0.8       , 0.80377358, 0.80377358,\n",
       "        0.80566038, 0.80566038, 0.81509434, 0.81509434, 0.81698113,\n",
       "        0.81698113, 0.81886792, 0.81886792, 0.82075472, 0.82075472,\n",
       "        0.8245283 , 0.8245283 , 0.82641509, 0.82641509, 0.83018868,\n",
       "        0.83018868, 0.83207547, 0.83207547, 0.83396226, 0.83396226,\n",
       "        0.83584906, 0.83584906, 0.83773585, 0.83773585, 0.83962264,\n",
       "        0.83962264, 0.84150943, 0.84150943, 0.84339623, 0.84339623,\n",
       "        0.84716981, 0.84716981, 0.8490566 , 0.8490566 , 0.85283019,\n",
       "        0.85283019, 0.85471698, 0.85471698, 0.86037736, 0.86037736,\n",
       "        0.86226415, 0.86226415, 0.86981132, 0.86981132, 0.87358491,\n",
       "        0.87358491, 0.8754717 , 0.8754717 , 0.89056604, 0.89056604,\n",
       "        0.89622642, 0.89622642, 0.91132075, 0.91132075, 0.91509434,\n",
       "        0.91509434, 0.91886792, 0.91886792, 0.9245283 , 0.9245283 ,\n",
       "        0.92830189, 0.92830189, 0.93018868, 0.93018868, 0.93584906,\n",
       "        0.93584906, 0.93773585, 0.93773585, 0.94150943, 0.94150943,\n",
       "        0.94716981, 0.94716981, 0.9490566 , 0.9490566 , 0.9509434 ,\n",
       "        0.9509434 , 0.95471698, 0.95471698, 0.95849057, 0.95849057,\n",
       "        0.96037736, 0.96037736, 0.96226415, 0.96226415, 0.96415094,\n",
       "        0.96415094, 0.96792453, 0.96792453, 0.96981132, 0.96981132,\n",
       "        0.97169811, 0.97169811, 0.97358491, 0.97358491, 0.9754717 ,\n",
       "        0.9754717 , 0.97924528, 0.97924528, 0.98113208, 0.98113208,\n",
       "        0.98301887, 0.98301887, 0.98490566, 0.98490566, 0.98679245,\n",
       "        0.98679245, 0.98867925, 0.98867925, 0.99056604, 0.99056604,\n",
       "        0.99245283, 0.99245283, 0.99622642, 0.99622642, 0.99811321,\n",
       "        0.99811321, 1.        , 1.        ]),\n",
       " 'Thresholds': array([       inf, 0.7881479 , 0.78043014, 0.78013206, 0.76310724,\n",
       "        0.7621871 , 0.7448284 , 0.7443406 , 0.7147867 , 0.69165486,\n",
       "        0.6892906 , 0.688663  , 0.6881112 , 0.68798625, 0.68566906,\n",
       "        0.68565196, 0.6777082 , 0.6772365 , 0.6697458 , 0.6690259 ,\n",
       "        0.66882193, 0.6680456 , 0.6663595 , 0.6643337 , 0.6639203 ,\n",
       "        0.6632717 , 0.66292393, 0.66189915, 0.66160464, 0.66159767,\n",
       "        0.66133255, 0.66099447, 0.66082543, 0.6606257 , 0.66044426,\n",
       "        0.6603278 , 0.6599867 , 0.6574813 , 0.6564416 , 0.65635   ,\n",
       "        0.6557873 , 0.65565664, 0.6543175 , 0.65417665, 0.6531733 ,\n",
       "        0.6531274 , 0.6527107 , 0.65267634, 0.6521121 , 0.6520786 ,\n",
       "        0.6518842 , 0.65187174, 0.65102714, 0.65093625, 0.6509189 ,\n",
       "        0.6508953 , 0.65072715, 0.6505981 , 0.6504183 , 0.6503841 ,\n",
       "        0.64913285, 0.6490766 , 0.64437896, 0.6442736 , 0.64415437,\n",
       "        0.64381164, 0.6430105 , 0.64271873, 0.64152706, 0.6414052 ,\n",
       "        0.64012676, 0.63964033, 0.6392862 , 0.6391496 , 0.63824666,\n",
       "        0.6372872 , 0.63345253, 0.6325704 , 0.62871933, 0.6281776 ,\n",
       "        0.625344  , 0.62348366, 0.618786  , 0.61727536, 0.6146406 ,\n",
       "        0.6127268 , 0.6121409 , 0.611306  , 0.6083155 , 0.6075321 ,\n",
       "        0.6039956 , 0.6013974 , 0.60068595, 0.6003093 , 0.5994308 ,\n",
       "        0.5979532 , 0.59684896, 0.5967363 , 0.5933217 , 0.59322417,\n",
       "        0.5902683 , 0.5893189 , 0.58710015, 0.5848374 , 0.5820478 ,\n",
       "        0.5813104 , 0.58056444, 0.580459  , 0.57484764, 0.57305753,\n",
       "        0.5700309 , 0.5692457 , 0.5681076 , 0.5672082 , 0.5656815 ,\n",
       "        0.5652517 , 0.55888236, 0.5581192 , 0.5535656 , 0.5499157 ,\n",
       "        0.54887545, 0.54582167, 0.5396489 , 0.5386842 , 0.5338023 ,\n",
       "        0.5269217 , 0.52349496, 0.522013  , 0.51231176, 0.50857323,\n",
       "        0.50834507, 0.5074547 , 0.50110996, 0.49868566, 0.49842662,\n",
       "        0.49840665, 0.4966752 , 0.49491066, 0.4930532 , 0.48565793,\n",
       "        0.48485804, 0.4811698 , 0.48033708, 0.47803456, 0.47610298,\n",
       "        0.4746066 , 0.47026166, 0.46274906, 0.4621622 , 0.4584883 ,\n",
       "        0.45842034, 0.4577484 , 0.4551503 , 0.453582  , 0.45351633,\n",
       "        0.4529364 , 0.4527009 , 0.45267653, 0.45202336, 0.45179376,\n",
       "        0.45146734, 0.4511966 , 0.45106286, 0.4503805 , 0.4495635 ,\n",
       "        0.448867  , 0.448404  , 0.44686037, 0.44663197, 0.44607243,\n",
       "        0.44583422, 0.44476324, 0.4440205 , 0.4433999 , 0.44112268,\n",
       "        0.4402792 , 0.44025508, 0.44002336, 0.43997365, 0.43621558,\n",
       "        0.43604   , 0.43394846, 0.43378496, 0.4331863 , 0.4326899 ,\n",
       "        0.4308382 , 0.43078166, 0.43064475, 0.4306373 , 0.43031532,\n",
       "        0.42987353, 0.4296287 , 0.42915457, 0.42880622, 0.4287807 ,\n",
       "        0.42854923, 0.4278438 , 0.4277336 , 0.42713585, 0.4271268 ,\n",
       "        0.4269995 , 0.42695737, 0.42650622, 0.42648235, 0.4256436 ,\n",
       "        0.424932  , 0.4247164 , 0.4245975 , 0.4244914 , 0.4243091 ,\n",
       "        0.42392477, 0.42383918, 0.42231002, 0.4223051 , 0.422089  ,\n",
       "        0.42200392, 0.42188254, 0.42132607, 0.42113146, 0.42079562,\n",
       "        0.4205719 , 0.42034578, 0.420273  , 0.41989312, 0.41966572,\n",
       "        0.41874522, 0.4185918 , 0.41770887, 0.4174579 , 0.41726223,\n",
       "        0.41692895, 0.4169278 , 0.41669464, 0.41668272, 0.4165693 ,\n",
       "        0.41639486, 0.4163178 , 0.41577083, 0.41571316, 0.41410917,\n",
       "        0.41397554, 0.41372484, 0.41315737, 0.41286287, 0.41208678,\n",
       "        0.41148156, 0.4089715 , 0.4081989 , 0.40742   , 0.4072606 ,\n",
       "        0.4069112 , 0.40601525, 0.40312546, 0.40113062, 0.400776  ,\n",
       "        0.40012723, 0.39995256, 0.3996483 , 0.3995722 , 0.3995153 ,\n",
       "        0.3987878 , 0.39755294, 0.3971774 , 0.39610094, 0.39604387,\n",
       "        0.39603055, 0.3956861 , 0.39530078, 0.39528155, 0.39352673,\n",
       "        0.39351106, 0.39193308, 0.3917932 , 0.39151853, 0.39144427,\n",
       "        0.38970774, 0.38967282, 0.3886765 , 0.3886527 , 0.3883962 ,\n",
       "        0.38823465, 0.38659307, 0.3865549 , 0.38642195, 0.386279  ,\n",
       "        0.38588384, 0.3858827 , 0.38583508, 0.38563788, 0.38544208,\n",
       "        0.38543952, 0.38531324, 0.3849383 , 0.38493592, 0.3848891 ,\n",
       "        0.38475493, 0.38461277, 0.38460463, 0.3840475 , 0.38389224,\n",
       "        0.38378274, 0.3836637 , 0.38307905, 0.38264632, 0.38232368,\n",
       "        0.38127738, 0.38107052, 0.38087422, 0.38021082, 0.37966502,\n",
       "        0.37830403, 0.3766511 , 0.3752865 , 0.37356904, 0.37217206,\n",
       "        0.3713172 , 0.37116075, 0.36907792, 0.36777475, 0.3674211 ,\n",
       "        0.36421388, 0.36332256, 0.3584461 , 0.33849838, 0.3375501 ,\n",
       "        0.3362462 , 0.33264583, 0.32774097, 0.32677132, 0.32585746,\n",
       "        0.32561392, 0.3234113 , 0.3232556 , 0.32199055, 0.32160842,\n",
       "        0.31784156, 0.31744626, 0.31379333, 0.31240723, 0.3122437 ,\n",
       "        0.31144947, 0.3045873 , 0.30303934, 0.30018443, 0.29993117,\n",
       "        0.29896122, 0.29862374, 0.29837158, 0.29723528, 0.29526013,\n",
       "        0.29515678, 0.29318616, 0.29271436, 0.2867592 , 0.2866165 ,\n",
       "        0.28461406, 0.28386384, 0.27344334, 0.2727132 , 0.27257118,\n",
       "        0.27221134, 0.2571011 , 0.2550903 , 0.23892243, 0.2384102 ,\n",
       "        0.23023358, 0.23016839, 0.22521944], dtype=float32),\n",
       " 'F1 Score': 0.6743697478991597,\n",
       " 'Accuracy': 0.7181818181818181,\n",
       " 'Recall': 0.6056603773584905,\n",
       " 'Precision': 0.7606635071090048,\n",
       " 'Confusion Matrix': array([[469, 101],\n",
       "        [209, 321]], dtype=int64)}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular las métricas\n",
    "metrics = clf_metrics(y_true, y_pred, y_prob)\n",
    "\n",
    "# Mostrar los resultados\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0.0 1.0]\n",
      "y_prob range: 0.22521944 0.7881479\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"y_true:\", np.unique(y_true))  # Debería mostrar solo 0 y 1\n",
    "print(\"y_prob range:\", y_prob.min(), y_prob.max())  # Debería estar entre 0 y 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antiguo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature   F-score   p-value\n",
      "0  feature_1  1.755164  0.188310\n",
      "1  feature_2  0.044922  0.832588\n",
      "2  feature_3  1.354646  0.247293\n",
      "3  feature_4  0.036762  0.848347\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Crear datos inventados\n",
    "np.random.seed(0)  # Fijar la semilla para reproducibilidad\n",
    "n_samples = 100  # Número de muestras\n",
    "\n",
    "# Crear características\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(0, 1, n_samples),\n",
    "    'feature_2': np.random.normal(1, 2, n_samples),\n",
    "    'feature_3': np.random.normal(-1, 1, n_samples),\n",
    "    'feature_4': np.random.normal(2, 3, n_samples)\n",
    "})\n",
    "\n",
    "# Crear etiquetas de clase (0 o 1)\n",
    "y = np.random.choice([0, 1], size=n_samples)\n",
    "\n",
    "# Calcular F-score y p-valores para cada característica\n",
    "f_scores, p_values = f_classif(X, y)\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "f_score_df = pd.DataFrame({'Feature': X.columns, 'F-score': f_scores, 'p-value': p_values})\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f_score_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_age_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
