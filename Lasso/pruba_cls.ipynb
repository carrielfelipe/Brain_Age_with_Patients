{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=  'C:/Users/felipe/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/'\n",
    "#import sys\n",
    "#sys.path.append(path) \n",
    "path_=  'C:/Users/felipe/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/Brain_Model/'\n",
    "import sys\n",
    "sys.path.append(path_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=  'C:/Users/felip/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/'\n",
    "#import sys\n",
    "#sys.path.append(path) \n",
    "path_=  'C:/Users/felip/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/Brain_Model/'\n",
    "import sys\n",
    "sys.path.append(path_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import shap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from nilearn import plotting\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "class BaseClassifier:\n",
    "    def __init__(self,save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None, model_params_search=None,fit_params_train=None, models_params_train=None, name_model=None):             \n",
    "       \n",
    "        self.scaler = scaler if scaler is not None else StandardScaler()\n",
    "        self.params = params if params is not None else {}\n",
    "        self.params_space = params_space if params_space is not None else {}\n",
    "        self.fit_params_search = fit_params_search if fit_params_search is not None else {}\n",
    "        self.model_params_search = model_params_search if model_params_search is not None else {}\n",
    "        self.fit_params_train = fit_params_train if fit_params_train is not None else {}\n",
    "        self.model_params_train = models_params_train if models_params_train is not None else {}\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.model_ml = None\n",
    "        self.name_model = name_model\n",
    "        self.model = None\n",
    "        self.opt_model = None\n",
    "        self.explainer = None\n",
    "\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "        self.x_train_kf = None\n",
    "        self.y_train_kf= None\n",
    "\n",
    "        self.early_stopping_rounds = 10\n",
    "\n",
    "        self.residual_model = None\n",
    "\n",
    "\n",
    "    def search_best_model(self,  X=None, y=None, param_space_=None, n_iter_=10, n_jobs_=-1, scoring_metric='accuracy', type_model=1):\n",
    "       \n",
    "        if X is None:\n",
    "            X = self.X_train\n",
    "        if y is None:\n",
    "            y = self.y_train\n",
    "\n",
    "        if param_space_ is None:\n",
    "            param_space = self.params_space\n",
    "        else:\n",
    "            param_space = param_space_\n",
    "\n",
    "        n_splits = 10\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=126)       \n",
    "        \n",
    "        if type_model == 1:\n",
    "            model = self.model_ml(**self.model_params_search)\n",
    "        if type_model == 2:\n",
    "            model = self.model_ml \n",
    "\n",
    "        opt_model = BayesSearchCV(\n",
    "            estimator=model,\n",
    "            search_spaces=param_space,\n",
    "            #fit_params=self.fit_param,\n",
    "            cv=kf,\n",
    "            n_iter=n_iter_,\n",
    "            #scoring=scoring_metric,\n",
    "            n_jobs=n_jobs_,\n",
    "            random_state=42,\n",
    "            verbose=1\n",
    "        )                \n",
    "        opt_model.fit(X, y, **self.fit_params_search)\n",
    "        best_params_return = dict(opt_model.best_params_)  \n",
    "\n",
    "        return opt_model, best_params_return\n",
    "    \n",
    "\n",
    "    def trainer(self, df, n_splits=10, n_iterations=20, params_=None, type_model=1, scaler=2, early_stop=False):\n",
    "        \n",
    "        if params_ is None:\n",
    "            params = self.params\n",
    "        else:\n",
    "            params = params_\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Preparar el dataframe de controles\n",
    "        X = df.iloc[:, :-2]  # Features\n",
    "        y = df.iloc[:, -2]   # Labels (Age)\n",
    "        ID = df.iloc[:, -1]  # IDs\n",
    "        results_per_fold_train = []\n",
    "        results_per_fold_test = []\n",
    "                \n",
    "        results_labels_df_train = pd.DataFrame(columns=['y_labels','y_pred','y_prob', 'ID-unique-2'])\n",
    "        results_labels_df_test = pd.DataFrame(columns=['y_labels', 'y_pred','y_prob', 'ID-unique-2'])\n",
    "\n",
    "        # Inicializar resultados\n",
    "        results = {'model': [],\n",
    "                    'mean_X_train_kf':[],\n",
    "                    'std_X_train_kf':[],\n",
    "                    'min_X_train_kf':[],\n",
    "                    'max_X_train_kf':[],\n",
    "                    'slope': [],\n",
    "                    'intercept': [],\n",
    "                    }\n",
    "        \n",
    "        # Bucle de iteraciones\n",
    "        for i in range(n_iterations):\n",
    "            # Crear validación cruzada para CN\n",
    "            kf_CN = KFold(n_splits=n_splits, shuffle=True, random_state=i)\n",
    "            kf_splits = list(kf_CN.split(X, y))\n",
    "            \n",
    "            for fold in range(n_splits):\n",
    "                # Obtener índices de entrenamiento y prueba para CN\n",
    "                train_index, test_index = kf_splits[fold]\n",
    "                X_train_kf, X_test_kf_CN = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train_kf, y_test_kf_CN = y.iloc[train_index], y.iloc[test_index]\n",
    "                id_train_kf = ID.iloc[train_index]\n",
    "                id_test_kf = ID.iloc[test_index]\n",
    "\n",
    "                mean_X_train_kf = X_train_kf.mean()\n",
    "                std_X_train_kf = X_train_kf.std()\n",
    "                min_X_train_kf = X_train_kf.min()\n",
    "                max_X_train_kf = X_train_kf.max()\n",
    "\n",
    "                # Escalar los datos de acuerdo con el parámetro scaler\n",
    "                if scaler == 1:\n",
    "                    # No escalar\n",
    "                    X_train_kf_scaled = X_train_kf\n",
    "                    X_test_kf_scaled = X_test_kf_CN\n",
    "                elif scaler == 2:\n",
    "                    # Z-score scaling                    \n",
    "                    X_train_kf_scaled = (X_train_kf - mean_X_train_kf) / std_X_train_kf\n",
    "                    X_test_kf_scaled = (X_test_kf_CN - mean_X_train_kf) / std_X_train_kf\n",
    "                elif scaler == 3:\n",
    "                    # MinMax scaling (manual)                    \n",
    "                    X_train_kf_scaled = (X_train_kf - min_X_train_kf) / (max_X_train_kf - min_X_train_kf)\n",
    "                    X_test_kf_scaled = (X_test_kf_CN - min_X_train_kf) / (max_X_train_kf - min_X_train_kf)\n",
    "\n",
    "                self.x_train_kf = X_train_kf_scaled\n",
    "                self.y_train_kf=y_train_kf\n",
    "\n",
    "\n",
    "                # Entrenar el modelo con CN\n",
    "                if type_model == 1:\n",
    "                    model = self.model_ml(**params, **self.model_params_train)\n",
    "                if type_model == 2:\n",
    "                    model = self.model_ml\n",
    "\n",
    "                if early_stop:\n",
    "                    self.fit_params_train = {\n",
    "                    \"early_stopping_rounds\": self.early_stopping_rounds,\n",
    "                    \"eval_set\": \"mae\",\n",
    "                    \"eval_set\": self.get_eval_set(),\n",
    "                    \"verbose\": False\n",
    "                    }\n",
    "\n",
    "                    \n",
    "                model.fit(X_train_kf_scaled, y_train_kf,**self.fit_params_train)\n",
    "\n",
    "                y_pred_CN_train = model.predict(X_train_kf_scaled)\n",
    "                y_prob_CN_train = model.predict_proba(X_train_kf_scaled)[:, 1]\n",
    "\n",
    "                # Hacer predicciones para el conjunto de prueba de CN\n",
    "                y_pred_CN_test = model.predict(X_test_kf_scaled)\n",
    "                y_prob_CN_test = model.predict_proba(X_test_kf_scaled)[:, 1]\n",
    "                \n",
    "                # Guardar resultados de CN \n",
    "                temp_CN_df_test = pd.DataFrame({\n",
    "                    'y_labels': y_test_kf_CN,\n",
    "                    'y_pred': y_pred_CN_test,\n",
    "                    'y_prob':y_prob_CN_test,                    \n",
    "                    'ID-unique-2': id_test_kf\n",
    "                })\n",
    "                temp_CN_df_train = pd.DataFrame({                    \n",
    "                    'y_labels': y_train_kf,\n",
    "                    'y_pred': y_pred_CN_train, \n",
    "                    'y_prob':y_prob_CN_train  ,                 \n",
    "                    'ID-unique-2': id_train_kf\n",
    "                })\n",
    "\n",
    "                results_labels_df_train = pd.concat([results_labels_df_train, temp_CN_df_train], ignore_index=True)\n",
    "                results_per_fold_train.append(temp_CN_df_train.copy())\n",
    "                results_labels_df_test = pd.concat([results_labels_df_test, temp_CN_df_test], ignore_index=True)\n",
    "                results_per_fold_test.append(temp_CN_df_test.copy())\n",
    "\n",
    "                # Procesar cada dataframe de pacientes si lista_dfs no es None\n",
    "                \n",
    "                # Guardar el modelo entrenado\n",
    "                results['model'].append(model)\n",
    "                \n",
    "                results['mean_X_train_kf'].append(mean_X_train_kf)\n",
    "                results['std_X_train_kf'].append(std_X_train_kf)\n",
    "            \n",
    "                results['min_X_train_kf'].append(min_X_train_kf)\n",
    "                results['max_X_train_kf'].append(max_X_train_kf)\n",
    "                \n",
    "                    \n",
    "\n",
    "        return results_labels_df_train, results_labels_df_test, results, results_per_fold_train,results_per_fold_test\n",
    "\n",
    "\n",
    "    def best_hyper(self, opt_model, num_best=10, num_max=400):\n",
    "        \"\"\"\n",
    "        Obtiene los mejores hiperparámetros para las mejores puntuaciones de validación cruzada dentro de los primeros num_max resultados.\n",
    "        \n",
    "        \"\"\"\n",
    "        results = opt_model.cv_results_\n",
    "        errors = results['mean_test_score'][:num_max]  # Considerar solo los primeros num_max resultados\n",
    "        best_idx = np.argsort(errors)[-num_best:]  # Obtener los índices de las mejores puntuaciones\n",
    "        best_hypers = []\n",
    "\n",
    "        for idx in best_idx:\n",
    "            hyper = {}\n",
    "            for param, value in results['params'][idx].items():\n",
    "                hyper[param] = value\n",
    "            best_hypers.append(hyper)\n",
    "\n",
    "        # Invertir el orden para que el mejor esté en el índice 0\n",
    "        best_hypers = best_hypers[::-1]\n",
    "\n",
    "        return best_hypers\n",
    "    \n",
    "    def avg_list(self, df_list):\n",
    "        results_avg = []\n",
    "        for df in df_list:            \n",
    "            df_avg = df.groupby('ID-unique-2').agg({\n",
    "                'y_labels': 'mean',\n",
    "                'y_pred': 'mean', \n",
    "                'y_prob': 'mean'               \n",
    "            }).reset_index()\n",
    "            results_avg.append(df_avg)\n",
    "        return results_avg\n",
    "    \n",
    "    def avg_list_threshold(self, df_list):\n",
    "        results_avg = []\n",
    "        for df in df_list:\n",
    "            df_avg = df.groupby('ID-unique-2').agg({\n",
    "                'y_labels': 'mean',\n",
    "                'y_pred': 'mean',\n",
    "                'y_prob': 'mean'\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Convertir el promedio de y_pred a 0 o 1 según el umbral de 0.5\n",
    "            df_avg['y_pred'] = (df_avg['y_pred'] >= 0.5).astype(int)\n",
    "            results_avg.append(df_avg)\n",
    "        return results_avg\n",
    "    \n",
    "    \n",
    "\n",
    "    def majority_vote(self, df_list):\n",
    "        results_avg = []\n",
    "        for df in df_list:\n",
    "            # Tomar la moda (valor más frecuente) para y_labels y y_pred\n",
    "            df_avg = df.groupby('ID-unique-2').agg({\n",
    "                'y_labels': lambda x: x.mode()[0],\n",
    "                'y_pred': lambda x: x.mode()[0],\n",
    "                'y_prob': lambda x: x.mode()[0]\n",
    "            }).reset_index()\n",
    "            results_avg.append(df_avg)\n",
    "        return results_avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#from base_regressor import BaseClassifier\n",
    "from Plotter import Plotter\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "class XGBoostClassifier(BaseClassifier):\n",
    "    def __init__(self, save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None, model_params_search=None, fit_params_train=None, model_params_train=None, name_model=\"Lasso\"):\n",
    "        super().__init__(save_path, scaler, params, params_space, fit_params_search, model_params_search, fit_params_train, model_params_train, name_model)\n",
    "\n",
    "        self.model_ml = xgb.XGBClassifier\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'alpha': 0.2,\n",
    "                'max_iter': 10000,\n",
    "                #'tol': 0.001\n",
    "            }\n",
    "        if params_space is None:\n",
    "            self.params_space = {\n",
    "                'objective'   : ['binary:logistic'],\n",
    "                'eval_metric' : ['logloss', 'error', 'auc', 'aucpr'],\n",
    "                'learning_rate': (0.01, 0.1, 0.2),\n",
    "                'max_depth': (3, 4, 5),\n",
    "                'subsample': (0.8, 0.9, 1.0),\n",
    "                'colsample_bytree': (0.8, 0.9, 1.0),\n",
    "                'reg_alpha': (0, 0.1, 1.0),\n",
    "                'reg_lambda': (0, 0.1, 1.0),\n",
    "                #'gamma': (0.001, 0.01, 0.1, 1, 10),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = XGBoostClassifier()\n",
    "Plotters = Plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los dataframes desde los archivos Excel\n",
    "df_CN_results_ = pd.read_excel('results/df_CN_results.xlsx')\n",
    "df_AD_results_ = pd.read_excel('results/df_AD_results.xlsx')\n",
    "df_FTD_results_ = pd.read_excel('results/df_FTD_results.xlsx')\n",
    "df_MCI_results_ = pd.read_excel('results/df_MCI_results.xlsx')\n",
    "df_PD_results_ = pd.read_excel('results/df_PD_results.xlsx')\n",
    "\n",
    "# Agregar la columna Diagnosis a cada dataframe antes de concatenar\n",
    "df_CN_results_['Diagnosis'] = 1  # CN\n",
    "df_AD_results_['Diagnosis'] = 2  # AD\n",
    "df_FTD_results_['Diagnosis'] = 2  # FTD\n",
    "df_MCI_results_['Diagnosis'] = 2  # MCI\n",
    "df_PD_results_['Diagnosis'] = 2  # PD\n",
    "\n",
    "\n",
    "\n",
    "# Combinar todos los dataframes\n",
    "df_results_combined = pd.concat([df_CN_results_, df_AD_results_, df_FTD_results_, df_MCI_results_, df_PD_results_], ignore_index=True)\n",
    "df_results_combined['ID-unique-2'] = range(len(df_results_combined))\n",
    "\n",
    "# Lista de columnas a limpiar\n",
    "columns_to_clean = ['Educ', 'Sex', 'MMSE', 'GINI']\n",
    "\n",
    "# Convertir las columnas a numérico, convirtiendo valores no numéricos a NaN\n",
    "df_results_combined[columns_to_clean] = df_results_combined[columns_to_clean].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Eliminar filas donde cualquiera de las columnas especificadas es NaN\n",
    "df_results_combined = df_results_combined.dropna(subset=columns_to_clean)\n",
    "\n",
    "# Resetear el índice después de eliminar las filas\n",
    "df_results_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "median_brain_age = df_results_combined['y_labels'].median()\n",
    "df_results_combined['brain_age_class'] = df_results_combined['y_labels'].apply(lambda x: 1 if x > median_brain_age else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID-unique</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_corrected</th>\n",
       "      <th>GAP</th>\n",
       "      <th>GAP_corrected</th>\n",
       "      <th>Country_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>HDI</th>\n",
       "      <th>GINI</th>\n",
       "      <th>ODQ</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>ID-unique-2</th>\n",
       "      <th>brain_age_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.975190</td>\n",
       "      <td>56.195626</td>\n",
       "      <td>11.975190</td>\n",
       "      <td>1.195626</td>\n",
       "      <td>CUB_123_2_sub-100035</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>98.976304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>62.0</td>\n",
       "      <td>69.369323</td>\n",
       "      <td>65.377834</td>\n",
       "      <td>7.369323</td>\n",
       "      <td>3.377834</td>\n",
       "      <td>CUB_123_1_sub-100012</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>99.691591</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.724968</td>\n",
       "      <td>69.631386</td>\n",
       "      <td>-0.275032</td>\n",
       "      <td>1.631386</td>\n",
       "      <td>CUB_62_sub-100037</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>95.638864</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>57.0</td>\n",
       "      <td>68.059997</td>\n",
       "      <td>59.231859</td>\n",
       "      <td>11.059997</td>\n",
       "      <td>2.231859</td>\n",
       "      <td>CUB_62_sub-100092</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>97.391599</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.206586</td>\n",
       "      <td>70.062372</td>\n",
       "      <td>-1.793414</td>\n",
       "      <td>1.062372</td>\n",
       "      <td>ARG_B1_sub-10002</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>41.793333</td>\n",
       "      <td>99.483527</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>35</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.433235</td>\n",
       "      <td>73.176533</td>\n",
       "      <td>-4.566765</td>\n",
       "      <td>1.176533</td>\n",
       "      <td>Chile_Tak_new_sub-100080</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.462338</td>\n",
       "      <td>2</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>36</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.155547</td>\n",
       "      <td>67.072363</td>\n",
       "      <td>1.155547</td>\n",
       "      <td>1.072363</td>\n",
       "      <td>Chile_Tak_new_sub-100083</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>98.270621</td>\n",
       "      <td>2</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>51</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.888157</td>\n",
       "      <td>73.651155</td>\n",
       "      <td>-4.111843</td>\n",
       "      <td>1.651155</td>\n",
       "      <td>Chile_Takeda_new_2_sub-100084</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.576163</td>\n",
       "      <td>2</td>\n",
       "      <td>1320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>52</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.263946</td>\n",
       "      <td>62.255509</td>\n",
       "      <td>4.263946</td>\n",
       "      <td>0.255509</td>\n",
       "      <td>Chile_Takeda_new_2_sub-100085</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.487833</td>\n",
       "      <td>2</td>\n",
       "      <td>1321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>53</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.717243</td>\n",
       "      <td>72.503415</td>\n",
       "      <td>-3.282757</td>\n",
       "      <td>1.503415</td>\n",
       "      <td>Chile_Takeda_new_2_sub-100086</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.531998</td>\n",
       "      <td>2</td>\n",
       "      <td>1322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID-unique  y_labels     y_pred  y_pred_corrected        GAP  \\\n",
       "0            27      55.0  66.975190         56.195626  11.975190   \n",
       "1            55      62.0  69.369323         65.377834   7.369323   \n",
       "2           111      68.0  67.724968         69.631386  -0.275032   \n",
       "3           161      57.0  68.059997         59.231859  11.059997   \n",
       "4           209      69.0  67.206586         70.062372  -1.793414   \n",
       "...         ...       ...        ...               ...        ...   \n",
       "1095         35      72.0  67.433235         73.176533  -4.566765   \n",
       "1096         36      66.0  67.155547         67.072363   1.155547   \n",
       "1097         51      72.0  67.888157         73.651155  -4.111843   \n",
       "1098         52      62.0  66.263946         62.255509   4.263946   \n",
       "1099         53      71.0  67.717243         72.503415  -3.282757   \n",
       "\n",
       "      GAP_corrected                     Country_ID   Age  Sex  Educ   MMSE  \\\n",
       "0          1.195626          CUB_123_2_sub-100035   55.0  2.0  13.0  30.00   \n",
       "1          3.377834          CUB_123_1_sub-100012   62.0  2.0  13.0  30.00   \n",
       "2          1.631386             CUB_62_sub-100037   68.0  2.0  10.0  30.00   \n",
       "3          2.231859             CUB_62_sub-100092   57.0  2.0  10.0  29.00   \n",
       "4          1.062372             ARG_B1_sub-10002    69.0  2.0  15.0  29.00   \n",
       "...             ...                            ...   ...  ...   ...    ...   \n",
       "1095       1.176533       Chile_Tak_new_sub-100080  72.0  1.0  15.0  29.96   \n",
       "1096       1.072363       Chile_Tak_new_sub-100083  66.0  1.0  14.0  29.17   \n",
       "1097       1.651155  Chile_Takeda_new_2_sub-100084  72.0  1.0  15.0  29.96   \n",
       "1098       0.255509  Chile_Takeda_new_2_sub-100085  62.0  1.0  13.0  32.33   \n",
       "1099       1.503415  Chile_Takeda_new_2_sub-100086  71.0  2.0  17.0  30.75   \n",
       "\n",
       "         HDI       GINI        ODQ  Diagnosis  ID-unique-2  brain_age_class  \n",
       "0     0.7578  40.700000  98.976304          1            1                0  \n",
       "1     0.7578  40.700000  99.691591          1            3                0  \n",
       "2     0.7578  40.700000  95.638864          1            5                0  \n",
       "3     0.7578  40.700000  97.391599          1            8                0  \n",
       "4     0.8510  41.793333  99.483527          1            9                0  \n",
       "...      ...        ...        ...        ...          ...              ...  \n",
       "1095     NaN  43.000000  99.462338          2         1304                1  \n",
       "1096     NaN  43.000000  98.270621          2         1305                0  \n",
       "1097     NaN  43.000000  99.576163          2         1320                1  \n",
       "1098     NaN  43.000000  99.487833          2         1321                0  \n",
       "1099     NaN  43.000000  99.531998          2         1322                1  \n",
       "\n",
       "[1100 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          3\n",
       "2          5\n",
       "3          8\n",
       "4          9\n",
       "        ... \n",
       "1095    1304\n",
       "1096    1305\n",
       "1097    1320\n",
       "1098    1321\n",
       "1099    1322\n",
       "Name: ID-unique-2, Length: 1100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_combined['ID-unique-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_results_combined[['Sex', 'Educ', 'MMSE', 'GINI', 'Diagnosis']]\n",
    "y = df_results_combined['brain_age_class']\n",
    "id = df_results_combined['ID-unique-2']\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "df_concatenado = pd.concat([X, y, id], axis=1, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df_concatenado, test_size=0.5, random_state=42, stratify=df_concatenado['Diagnosis']\n",
    ")\n",
    "\n",
    "# Combinar nuevamente train y test para obtener el dataset completo desordenado\n",
    "df_desordenado = pd.concat([df_train, df_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>GINI</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>brain_age_class</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>52.608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.22</td>\n",
       "      <td>45.300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>54.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>54.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>51.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>43.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>52.608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>51.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>52.700</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.22</td>\n",
       "      <td>41.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Educ   MMSE    GINI  Diagnosis  brain_age_class  ID-unique-2\n",
       "0     2.0  11.0  26.00  52.608          1                1          320\n",
       "1     2.0  12.0  25.22  45.300          2                0          884\n",
       "2     2.0  10.0  27.00  54.800          2                1         1133\n",
       "3     1.0   8.0  26.00  54.800          2                1          744\n",
       "4     2.0  11.0  29.00  51.500          1                0          581\n",
       "...   ...   ...    ...     ...        ...              ...          ...\n",
       "1095  2.0  11.0  25.00  43.500          2                1          938\n",
       "1096  2.0   4.0  25.00  52.608          1                1          332\n",
       "1097  2.0  19.0  28.00  51.500          1                0          533\n",
       "1098  2.0  11.0  15.00  52.700          2                1          762\n",
       "1099  2.0  18.0  24.22  41.800          2                1          681\n",
       "\n",
       "[1100 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desordenado = df_desordenado[['Sex', 'Educ', 'MMSE', 'GINI', 'Diagnosis']]\n",
    "y_desordenado= df_desordenado['brain_age_class']\n",
    "id_desordenado = df_desordenado['ID-unique-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenado_desordenado = pd.concat([X_desordenado, y_desordenado, id_desordenado], axis=1, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>GINI</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>brain_age_class</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>52.608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.22</td>\n",
       "      <td>45.300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>54.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>54.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>51.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>43.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>52.608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>51.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>52.700</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.22</td>\n",
       "      <td>41.800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Educ   MMSE    GINI  Diagnosis  brain_age_class  ID-unique-2\n",
       "0     2.0  11.0  26.00  52.608          1                1          320\n",
       "1     2.0  12.0  25.22  45.300          2                0          884\n",
       "2     2.0  10.0  27.00  54.800          2                1         1133\n",
       "3     1.0   8.0  26.00  54.800          2                1          744\n",
       "4     2.0  11.0  29.00  51.500          1                0          581\n",
       "...   ...   ...    ...     ...        ...              ...          ...\n",
       "1095  2.0  11.0  25.00  43.500          2                1          938\n",
       "1096  2.0   4.0  25.00  52.608          1                1          332\n",
       "1097  2.0  19.0  28.00  51.500          1                0          533\n",
       "1098  2.0  11.0  15.00  52.700          2                1          762\n",
       "1099  2.0  18.0  24.22  41.800          2                1          681\n",
       "\n",
       "[1100 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado_desordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "opt_model_cls, best_params_cls =model_cls.search_best_model(X=X_desordenado, y=y_desordenado, n_iter_=10, scoring_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'eval_metric': 'aucpr',\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 4,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.1,\n",
       " 'reg_lambda': 0,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 4,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 1.0},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 3,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.8,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 3,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'auc',\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 3,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 1.0},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'logloss',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 1.0,\n",
       "  'subsample': 1.0},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'error',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 1.0,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.9,\n",
       "  'eval_metric': 'aucpr',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0.1,\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 1.0,\n",
       "  'eval_metric': 'auc',\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 4,\n",
       "  'objective': 'binary:logistic',\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0,\n",
       "  'subsample': 0.9}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_cls_ = model_cls.best_hyper(num_best=10, opt_model=opt_model_cls, num_max=50)\n",
    "best_params_cls_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educ</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>GINI</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>brain_age_class</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>41.793333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.17</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.33</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.75</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Educ   MMSE       GINI  Diagnosis  brain_age_class  ID-unique-2\n",
       "0     2.0  13.0  30.00  40.700000          1                0            1\n",
       "1     2.0  13.0  30.00  40.700000          1                0            3\n",
       "2     2.0  10.0  30.00  40.700000          1                0            5\n",
       "3     2.0  10.0  29.00  40.700000          1                0            8\n",
       "4     2.0  15.0  29.00  41.793333          1                0            9\n",
       "...   ...   ...    ...        ...        ...              ...          ...\n",
       "1095  1.0  15.0  29.96  43.000000          2                1         1304\n",
       "1096  1.0  14.0  29.17  43.000000          2                0         1305\n",
       "1097  1.0  15.0  29.96  43.000000          2                1         1320\n",
       "1098  1.0  13.0  32.33  43.000000          2                0         1321\n",
       "1099  2.0  17.0  30.75  43.000000          2                1         1322\n",
       "\n",
       "[1100 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Local\\Temp\\ipykernel_76408\\3338887986.py:197: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_labels_df_train = pd.concat([results_labels_df_train, temp_CN_df_train], ignore_index=True)\n",
      "C:\\Users\\felip\\AppData\\Local\\Temp\\ipykernel_76408\\3338887986.py:199: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_labels_df_test = pd.concat([results_labels_df_test, temp_CN_df_test], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_labels_df_train, results_labels_df_test,  results_model, results_per_fold_train, results_per_fold_test = model_cls.trainer(df=df_concatenado_desordenado, n_splits=10, n_iterations=20, params_=best_params_cls_[0], scaler=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_test.to_excel('results/df_prueba___.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_labels</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>ID-unique-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643350</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289121</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361237</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385269</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512546</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411784</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447585</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345880</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654260</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791159</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_labels y_pred    y_prob ID-unique-2\n",
       "0            0      1  0.643350         884\n",
       "1            0      0  0.289121        1147\n",
       "2            1      0  0.361237         249\n",
       "3            0      0  0.385269          20\n",
       "4            0      1  0.512546         835\n",
       "...        ...    ...       ...         ...\n",
       "21995        1      0  0.411784        1003\n",
       "21996        0      0  0.447585        1283\n",
       "21997        0      0  0.345880         275\n",
       "21998        1      1  0.654260         908\n",
       "21999        1      1  0.791159         778\n",
       "\n",
       "[22000 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_labels_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_total = [results_labels_df_test]\n",
    "results_avg_list = model_cls.avg_list(results_labels_df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID-unique-2</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID-unique-2 y_labels y_pred    y_prob\n",
       "0               1      0.0    0.0  0.387503\n",
       "1               3      0.0    0.0  0.389980\n",
       "2               5      0.0    0.0  0.388100\n",
       "3               8      0.0    0.0  0.392020\n",
       "4               9      0.0    0.0  0.385906\n",
       "...           ...      ...    ...       ...\n",
       "1095         1304      1.0    0.0  0.446632\n",
       "1096         1305      0.0    0.0  0.445375\n",
       "1097         1320      1.0    0.0  0.446678\n",
       "1098         1321      0.0    0.0  0.428901\n",
       "1099         1322      1.0    0.0  0.412228\n",
       "\n",
       "[1100 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_avg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      y_labels y_pred    y_prob ID-unique-2\n",
       " 0            0      1  0.643350         884\n",
       " 1            0      0  0.289121        1147\n",
       " 2            1      0  0.361237         249\n",
       " 3            0      0  0.385269          20\n",
       " 4            0      1  0.512546         835\n",
       " ...        ...    ...       ...         ...\n",
       " 21995        1      0  0.411784        1003\n",
       " 21996        0      0  0.447585        1283\n",
       " 21997        0      0  0.345880         275\n",
       " 21998        1      1  0.654260         908\n",
       " 21999        1      1  0.791159         778\n",
       " \n",
       " [22000 rows x 4 columns]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_labels_df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID-unique-2 y_labels  y_pred    y_prob\n",
      "0               1      0.0       0  0.387503\n",
      "1               3      0.0       0  0.389980\n",
      "2               5      0.0       0  0.388100\n",
      "3               8      0.0       0  0.392020\n",
      "4               9      0.0       0  0.385906\n",
      "...           ...      ...     ...       ...\n",
      "1095         1304      1.0       0  0.446632\n",
      "1096         1305      0.0       0  0.445375\n",
      "1097         1320      1.0       0  0.446678\n",
      "1098         1321      0.0       0  0.428901\n",
      "1099         1322      1.0       0  0.412228\n",
      "\n",
      "[1100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "results_avg_list = model_cls.avg_list_threshold(results_labels_df_total)\n",
    "print(results_avg_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID-unique-2  y_labels  y_pred    y_prob\n",
      "0               1         0       0  0.377585\n",
      "1               3         0       0  0.380182\n",
      "2               5         0       0  0.367036\n",
      "3               8         0       0  0.379105\n",
      "4               9         0       0  0.371979\n",
      "...           ...       ...     ...       ...\n",
      "1095         1304         1       0  0.429422\n",
      "1096         1305         0       0  0.425091\n",
      "1097         1320         1       0  0.431485\n",
      "1098         1321         0       0  0.407550\n",
      "1099         1322         1       0  0.385063\n",
      "\n",
      "[1100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "results_avg_list = model_cls.majority_vote(results_labels_df_total)\n",
    "print(results_avg_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_avg_list[0].to_excel('results/df_prueba_ttttest.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.387503\n",
       "1       0.389980\n",
       "2       0.388100\n",
       "3       0.392020\n",
       "4       0.385906\n",
       "          ...   \n",
       "1095    0.446632\n",
       "1096    0.445375\n",
       "1097    0.446678\n",
       "1098    0.428901\n",
       "1099    0.412228\n",
       "Name: y_prob, Length: 1100, dtype: float32"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_avg_list[0]['y_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# Suponiendo que `y_prob` es una probabilidad predicha; aquí se usa una probabilidad de ejemplo.\n",
    "y_true = results_avg_list[0]['y_labels']\n",
    "y_pred = results_avg_list[0]['y_pred']\n",
    "y_prob = results_avg_list[0]['y_prob'] # Reemplazar con las probabilidades reales\n",
    "\n",
    "# Definir la función de métricas de clasificación\n",
    "def clf_metrics(y_true, y_pred, y_prob):\n",
    "    # ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    \n",
    "    # Otras métricas de clasificación\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        \"AUC\": auc_value,\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr,\n",
    "        \"Thresholds\": thresholds,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"Precision\": precision,\n",
    "        \"Confusion Matrix\": cm\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.387503\n",
       "1       0.389980\n",
       "2       0.388100\n",
       "3       0.392020\n",
       "4       0.385906\n",
       "          ...   \n",
       "1095    0.446632\n",
       "1096    0.445375\n",
       "1097    0.446678\n",
       "1098    0.428901\n",
       "1099    0.412228\n",
       "Name: y_prob, Length: 1100, dtype: float32"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.7599834491890104,\n",
       " 'FPR': array([0.        , 0.00175439, 0.00175439, 0.00350877, 0.00350877,\n",
       "        0.00526316, 0.00526316, 0.00701754, 0.00701754, 0.01754386,\n",
       "        0.01754386, 0.02280702, 0.02280702, 0.0245614 , 0.0245614 ,\n",
       "        0.02631579, 0.02631579, 0.02807018, 0.02807018, 0.03157895,\n",
       "        0.03157895, 0.03333333, 0.03333333, 0.03684211, 0.03684211,\n",
       "        0.04035088, 0.04035088, 0.04561404, 0.04561404, 0.04736842,\n",
       "        0.04736842, 0.04912281, 0.04912281, 0.05087719, 0.05087719,\n",
       "        0.05263158, 0.05263158, 0.06140351, 0.06140351, 0.06315789,\n",
       "        0.06315789, 0.06491228, 0.06491228, 0.06842105, 0.06842105,\n",
       "        0.07017544, 0.07017544, 0.07192982, 0.07192982, 0.07368421,\n",
       "        0.07368421, 0.0754386 , 0.0754386 , 0.07719298, 0.07719298,\n",
       "        0.07894737, 0.07894737, 0.08070175, 0.08070175, 0.08245614,\n",
       "        0.08245614, 0.08421053, 0.08421053, 0.08596491, 0.08596491,\n",
       "        0.0877193 , 0.0877193 , 0.08947368, 0.08947368, 0.09122807,\n",
       "        0.09122807, 0.09298246, 0.09298246, 0.09473684, 0.09473684,\n",
       "        0.09649123, 0.09649123, 0.1       , 0.1       , 0.10175439,\n",
       "        0.10175439, 0.10350877, 0.10350877, 0.10701754, 0.10701754,\n",
       "        0.11403509, 0.11403509, 0.11578947, 0.11578947, 0.11754386,\n",
       "        0.11754386, 0.12105263, 0.12105263, 0.12280702, 0.12280702,\n",
       "        0.1245614 , 0.1245614 , 0.12631579, 0.12631579, 0.12807018,\n",
       "        0.12807018, 0.12982456, 0.12982456, 0.13684211, 0.13684211,\n",
       "        0.13859649, 0.13859649, 0.14035088, 0.14035088, 0.14210526,\n",
       "        0.14210526, 0.14385965, 0.14385965, 0.14561404, 0.14561404,\n",
       "        0.14736842, 0.14736842, 0.14912281, 0.14912281, 0.15438596,\n",
       "        0.15438596, 0.15789474, 0.15789474, 0.15964912, 0.15964912,\n",
       "        0.16315789, 0.16315789, 0.16491228, 0.16491228, 0.17017544,\n",
       "        0.17017544, 0.17368421, 0.17368421, 0.17719298, 0.17719298,\n",
       "        0.17894737, 0.17894737, 0.18070175, 0.18070175, 0.18947368,\n",
       "        0.18947368, 0.19122807, 0.19122807, 0.2       , 0.2       ,\n",
       "        0.20350877, 0.20350877, 0.21403509, 0.21403509, 0.22105263,\n",
       "        0.22105263, 0.2245614 , 0.2245614 , 0.22807018, 0.22807018,\n",
       "        0.23157895, 0.23157895, 0.23333333, 0.23333333, 0.23508772,\n",
       "        0.23508772, 0.23684211, 0.23684211, 0.23859649, 0.23859649,\n",
       "        0.24385965, 0.24385965, 0.25263158, 0.25263158, 0.25964912,\n",
       "        0.25964912, 0.26842105, 0.26842105, 0.27192982, 0.27192982,\n",
       "        0.27368421, 0.27368421, 0.2754386 , 0.2754386 , 0.29649123,\n",
       "        0.29649123, 0.31052632, 0.31052632, 0.3122807 , 0.3122807 ,\n",
       "        0.33684211, 0.33684211, 0.33859649, 0.33859649, 0.34210526,\n",
       "        0.34210526, 0.34561404, 0.34561404, 0.34912281, 0.34912281,\n",
       "        0.35438596, 0.35438596, 0.35789474, 0.35789474, 0.35964912,\n",
       "        0.35964912, 0.36140351, 0.36140351, 0.36315789, 0.36315789,\n",
       "        0.36491228, 0.36491228, 0.36666667, 0.36666667, 0.36842105,\n",
       "        0.36842105, 0.37192982, 0.37192982, 0.37368421, 0.37368421,\n",
       "        0.3754386 , 0.3754386 , 0.37894737, 0.37894737, 0.38245614,\n",
       "        0.38245614, 0.38596491, 0.38596491, 0.38947368, 0.38947368,\n",
       "        0.39473684, 0.39473684, 0.40701754, 0.40701754, 0.41052632,\n",
       "        0.41052632, 0.4122807 , 0.4122807 , 0.41403509, 0.41403509,\n",
       "        0.41578947, 0.41578947, 0.41929825, 0.41929825, 0.42807018,\n",
       "        0.42807018, 0.43157895, 0.43157895, 0.43333333, 0.43333333,\n",
       "        0.44035088, 0.44035088, 0.44385965, 0.44385965, 0.44561404,\n",
       "        0.44561404, 0.45087719, 0.45087719, 0.45789474, 0.45789474,\n",
       "        0.46315789, 0.46315789, 0.46491228, 0.46491228, 0.46666667,\n",
       "        0.46666667, 0.46842105, 0.46842105, 0.47368421, 0.47368421,\n",
       "        0.4754386 , 0.4754386 , 0.47719298, 0.47719298, 0.48245614,\n",
       "        0.48245614, 0.49824561, 0.49824561, 0.50350877, 0.50350877,\n",
       "        0.54210526, 0.54210526, 0.56666667, 0.56666667, 0.5754386 ,\n",
       "        0.5754386 , 0.62280702, 0.62280702, 0.6245614 , 0.6245614 ,\n",
       "        0.62982456, 0.62982456, 0.63333333, 0.63333333, 0.63508772,\n",
       "        0.63508772, 0.64035088, 0.64035088, 0.64210526, 0.64210526,\n",
       "        0.64561404, 0.64561404, 0.64736842, 0.64736842, 0.65087719,\n",
       "        0.65087719, 0.65438596, 0.65438596, 0.65964912, 0.65964912,\n",
       "        0.66842105, 0.66842105, 0.67368421, 0.67368421, 0.67719298,\n",
       "        0.67719298, 0.68421053, 0.68421053, 0.6877193 , 0.6877193 ,\n",
       "        0.68947368, 0.68947368, 0.69473684, 0.69473684, 0.69824561,\n",
       "        0.69824561, 0.7       , 0.7       , 0.74035088, 0.74035088,\n",
       "        0.74561404, 0.74561404, 0.75614035, 0.75614035, 0.75964912,\n",
       "        0.75964912, 0.76491228, 0.76491228, 0.77368421, 0.77368421,\n",
       "        0.8       , 0.8       , 0.81403509, 0.81403509, 0.81578947,\n",
       "        0.81578947, 0.83684211, 0.83684211, 0.84385965, 0.84385965,\n",
       "        0.84561404, 0.84561404, 0.84736842, 0.84736842, 0.85087719,\n",
       "        0.85087719, 0.86315789, 0.86315789, 0.87719298, 0.87719298,\n",
       "        0.88070175, 0.88070175, 0.90526316, 0.90526316, 0.90701754,\n",
       "        0.90701754, 0.94736842, 0.94736842, 0.95789474, 0.95789474,\n",
       "        0.9877193 , 0.9877193 , 1.        ]),\n",
       " 'TPR': array([0.        , 0.        , 0.00188679, 0.00188679, 0.06226415,\n",
       "        0.06226415, 0.08113208, 0.08113208, 0.1       , 0.1       ,\n",
       "        0.10188679, 0.10188679, 0.10377358, 0.10377358, 0.11132075,\n",
       "        0.11132075, 0.17924528, 0.17924528, 0.2       , 0.2       ,\n",
       "        0.20188679, 0.20188679, 0.20377358, 0.20377358, 0.20754717,\n",
       "        0.20754717, 0.21132075, 0.21132075, 0.21509434, 0.21509434,\n",
       "        0.21698113, 0.21698113, 0.22075472, 0.22075472, 0.22264151,\n",
       "        0.22264151, 0.2245283 , 0.2245283 , 0.23396226, 0.23396226,\n",
       "        0.23962264, 0.23962264, 0.25283019, 0.25283019, 0.25849057,\n",
       "        0.25849057, 0.26603774, 0.26603774, 0.26981132, 0.26981132,\n",
       "        0.27924528, 0.27924528, 0.28867925, 0.28867925, 0.29056604,\n",
       "        0.29056604, 0.29433962, 0.29433962, 0.29811321, 0.29811321,\n",
       "        0.31132075, 0.31132075, 0.39245283, 0.39245283, 0.39622642,\n",
       "        0.39622642, 0.40377358, 0.40377358, 0.40754717, 0.40754717,\n",
       "        0.41509434, 0.41509434, 0.41698113, 0.41698113, 0.42075472,\n",
       "        0.42075472, 0.42641509, 0.42641509, 0.43207547, 0.43207547,\n",
       "        0.43962264, 0.43962264, 0.45471698, 0.45471698, 0.46226415,\n",
       "        0.46226415, 0.46415094, 0.46415094, 0.4754717 , 0.4754717 ,\n",
       "        0.47924528, 0.47924528, 0.48679245, 0.48679245, 0.49245283,\n",
       "        0.49245283, 0.49811321, 0.49811321, 0.50943396, 0.50943396,\n",
       "        0.51886792, 0.51886792, 0.52264151, 0.52264151, 0.53018868,\n",
       "        0.53018868, 0.53207547, 0.53207547, 0.54339623, 0.54339623,\n",
       "        0.54716981, 0.54716981, 0.5490566 , 0.5490566 , 0.55471698,\n",
       "        0.55471698, 0.56981132, 0.56981132, 0.57358491, 0.57358491,\n",
       "        0.5754717 , 0.5754717 , 0.57735849, 0.57735849, 0.58301887,\n",
       "        0.58301887, 0.58867925, 0.58867925, 0.59433962, 0.59433962,\n",
       "        0.59622642, 0.59622642, 0.60377358, 0.60377358, 0.60566038,\n",
       "        0.60566038, 0.60943396, 0.60943396, 0.61132075, 0.61132075,\n",
       "        0.61320755, 0.61320755, 0.61698113, 0.61698113, 0.61886792,\n",
       "        0.61886792, 0.6245283 , 0.6245283 , 0.62830189, 0.62830189,\n",
       "        0.63018868, 0.63018868, 0.63962264, 0.63962264, 0.64150943,\n",
       "        0.64150943, 0.64339623, 0.64339623, 0.64528302, 0.64528302,\n",
       "        0.64716981, 0.64716981, 0.6490566 , 0.6490566 , 0.65283019,\n",
       "        0.65283019, 0.65471698, 0.65471698, 0.66037736, 0.66037736,\n",
       "        0.66226415, 0.66226415, 0.66415094, 0.66415094, 0.66792453,\n",
       "        0.66792453, 0.66981132, 0.66981132, 0.67169811, 0.67169811,\n",
       "        0.67358491, 0.67358491, 0.6754717 , 0.6754717 , 0.67924528,\n",
       "        0.67924528, 0.68113208, 0.68113208, 0.68301887, 0.68301887,\n",
       "        0.68490566, 0.68490566, 0.69245283, 0.69245283, 0.69433962,\n",
       "        0.69433962, 0.70188679, 0.70188679, 0.70566038, 0.70566038,\n",
       "        0.70943396, 0.70943396, 0.71132075, 0.71132075, 0.71886792,\n",
       "        0.71886792, 0.72075472, 0.72075472, 0.72264151, 0.72264151,\n",
       "        0.73207547, 0.73207547, 0.74528302, 0.74528302, 0.7509434 ,\n",
       "        0.7509434 , 0.75283019, 0.75283019, 0.75660377, 0.75660377,\n",
       "        0.75849057, 0.75849057, 0.76037736, 0.76037736, 0.76226415,\n",
       "        0.76226415, 0.76415094, 0.76415094, 0.76603774, 0.76603774,\n",
       "        0.76792453, 0.76792453, 0.76981132, 0.76981132, 0.77358491,\n",
       "        0.77358491, 0.7754717 , 0.7754717 , 0.77924528, 0.77924528,\n",
       "        0.78113208, 0.78113208, 0.78301887, 0.78301887, 0.79056604,\n",
       "        0.79056604, 0.8       , 0.8       , 0.80377358, 0.80377358,\n",
       "        0.80566038, 0.80566038, 0.81509434, 0.81509434, 0.81698113,\n",
       "        0.81698113, 0.81886792, 0.81886792, 0.82075472, 0.82075472,\n",
       "        0.8245283 , 0.8245283 , 0.82641509, 0.82641509, 0.83018868,\n",
       "        0.83018868, 0.83207547, 0.83207547, 0.83396226, 0.83396226,\n",
       "        0.83584906, 0.83584906, 0.83773585, 0.83773585, 0.83962264,\n",
       "        0.83962264, 0.84150943, 0.84150943, 0.84339623, 0.84339623,\n",
       "        0.84716981, 0.84716981, 0.8490566 , 0.8490566 , 0.85283019,\n",
       "        0.85283019, 0.85471698, 0.85471698, 0.86037736, 0.86037736,\n",
       "        0.86226415, 0.86226415, 0.86981132, 0.86981132, 0.87358491,\n",
       "        0.87358491, 0.8754717 , 0.8754717 , 0.89056604, 0.89056604,\n",
       "        0.89622642, 0.89622642, 0.91132075, 0.91132075, 0.91509434,\n",
       "        0.91509434, 0.91886792, 0.91886792, 0.9245283 , 0.9245283 ,\n",
       "        0.92830189, 0.92830189, 0.93018868, 0.93018868, 0.93584906,\n",
       "        0.93584906, 0.93773585, 0.93773585, 0.94150943, 0.94150943,\n",
       "        0.94716981, 0.94716981, 0.9490566 , 0.9490566 , 0.9509434 ,\n",
       "        0.9509434 , 0.95471698, 0.95471698, 0.95849057, 0.95849057,\n",
       "        0.96037736, 0.96037736, 0.96226415, 0.96226415, 0.96415094,\n",
       "        0.96415094, 0.96792453, 0.96792453, 0.96981132, 0.96981132,\n",
       "        0.97169811, 0.97169811, 0.97358491, 0.97358491, 0.9754717 ,\n",
       "        0.9754717 , 0.97924528, 0.97924528, 0.98113208, 0.98113208,\n",
       "        0.98301887, 0.98301887, 0.98490566, 0.98490566, 0.98679245,\n",
       "        0.98679245, 0.98867925, 0.98867925, 0.99056604, 0.99056604,\n",
       "        0.99245283, 0.99245283, 0.99622642, 0.99622642, 0.99811321,\n",
       "        0.99811321, 1.        , 1.        ]),\n",
       " 'Thresholds': array([       inf, 0.7881479 , 0.78043014, 0.78013206, 0.76310724,\n",
       "        0.7621871 , 0.7448284 , 0.7443406 , 0.7147867 , 0.69165486,\n",
       "        0.6892906 , 0.688663  , 0.6881112 , 0.68798625, 0.68566906,\n",
       "        0.68565196, 0.6777082 , 0.6772365 , 0.6697458 , 0.6690259 ,\n",
       "        0.66882193, 0.6680456 , 0.6663595 , 0.6643337 , 0.6639203 ,\n",
       "        0.6632717 , 0.66292393, 0.66189915, 0.66160464, 0.66159767,\n",
       "        0.66133255, 0.66099447, 0.66082543, 0.6606257 , 0.66044426,\n",
       "        0.6603278 , 0.6599867 , 0.6574813 , 0.6564416 , 0.65635   ,\n",
       "        0.6557873 , 0.65565664, 0.6543175 , 0.65417665, 0.6531733 ,\n",
       "        0.6531274 , 0.6527107 , 0.65267634, 0.6521121 , 0.6520786 ,\n",
       "        0.6518842 , 0.65187174, 0.65102714, 0.65093625, 0.6509189 ,\n",
       "        0.6508953 , 0.65072715, 0.6505981 , 0.6504183 , 0.6503841 ,\n",
       "        0.64913285, 0.6490766 , 0.64437896, 0.6442736 , 0.64415437,\n",
       "        0.64381164, 0.6430105 , 0.64271873, 0.64152706, 0.6414052 ,\n",
       "        0.64012676, 0.63964033, 0.6392862 , 0.6391496 , 0.63824666,\n",
       "        0.6372872 , 0.63345253, 0.6325704 , 0.62871933, 0.6281776 ,\n",
       "        0.625344  , 0.62348366, 0.618786  , 0.61727536, 0.6146406 ,\n",
       "        0.6127268 , 0.6121409 , 0.611306  , 0.6083155 , 0.6075321 ,\n",
       "        0.6039956 , 0.6013974 , 0.60068595, 0.6003093 , 0.5994308 ,\n",
       "        0.5979532 , 0.59684896, 0.5967363 , 0.5933217 , 0.59322417,\n",
       "        0.5902683 , 0.5893189 , 0.58710015, 0.5848374 , 0.5820478 ,\n",
       "        0.5813104 , 0.58056444, 0.580459  , 0.57484764, 0.57305753,\n",
       "        0.5700309 , 0.5692457 , 0.5681076 , 0.5672082 , 0.5656815 ,\n",
       "        0.5652517 , 0.55888236, 0.5581192 , 0.5535656 , 0.5499157 ,\n",
       "        0.54887545, 0.54582167, 0.5396489 , 0.5386842 , 0.5338023 ,\n",
       "        0.5269217 , 0.52349496, 0.522013  , 0.51231176, 0.50857323,\n",
       "        0.50834507, 0.5074547 , 0.50110996, 0.49868566, 0.49842662,\n",
       "        0.49840665, 0.4966752 , 0.49491066, 0.4930532 , 0.48565793,\n",
       "        0.48485804, 0.4811698 , 0.48033708, 0.47803456, 0.47610298,\n",
       "        0.4746066 , 0.47026166, 0.46274906, 0.4621622 , 0.4584883 ,\n",
       "        0.45842034, 0.4577484 , 0.4551503 , 0.453582  , 0.45351633,\n",
       "        0.4529364 , 0.4527009 , 0.45267653, 0.45202336, 0.45179376,\n",
       "        0.45146734, 0.4511966 , 0.45106286, 0.4503805 , 0.4495635 ,\n",
       "        0.448867  , 0.448404  , 0.44686037, 0.44663197, 0.44607243,\n",
       "        0.44583422, 0.44476324, 0.4440205 , 0.4433999 , 0.44112268,\n",
       "        0.4402792 , 0.44025508, 0.44002336, 0.43997365, 0.43621558,\n",
       "        0.43604   , 0.43394846, 0.43378496, 0.4331863 , 0.4326899 ,\n",
       "        0.4308382 , 0.43078166, 0.43064475, 0.4306373 , 0.43031532,\n",
       "        0.42987353, 0.4296287 , 0.42915457, 0.42880622, 0.4287807 ,\n",
       "        0.42854923, 0.4278438 , 0.4277336 , 0.42713585, 0.4271268 ,\n",
       "        0.4269995 , 0.42695737, 0.42650622, 0.42648235, 0.4256436 ,\n",
       "        0.424932  , 0.4247164 , 0.4245975 , 0.4244914 , 0.4243091 ,\n",
       "        0.42392477, 0.42383918, 0.42231002, 0.4223051 , 0.422089  ,\n",
       "        0.42200392, 0.42188254, 0.42132607, 0.42113146, 0.42079562,\n",
       "        0.4205719 , 0.42034578, 0.420273  , 0.41989312, 0.41966572,\n",
       "        0.41874522, 0.4185918 , 0.41770887, 0.4174579 , 0.41726223,\n",
       "        0.41692895, 0.4169278 , 0.41669464, 0.41668272, 0.4165693 ,\n",
       "        0.41639486, 0.4163178 , 0.41577083, 0.41571316, 0.41410917,\n",
       "        0.41397554, 0.41372484, 0.41315737, 0.41286287, 0.41208678,\n",
       "        0.41148156, 0.4089715 , 0.4081989 , 0.40742   , 0.4072606 ,\n",
       "        0.4069112 , 0.40601525, 0.40312546, 0.40113062, 0.400776  ,\n",
       "        0.40012723, 0.39995256, 0.3996483 , 0.3995722 , 0.3995153 ,\n",
       "        0.3987878 , 0.39755294, 0.3971774 , 0.39610094, 0.39604387,\n",
       "        0.39603055, 0.3956861 , 0.39530078, 0.39528155, 0.39352673,\n",
       "        0.39351106, 0.39193308, 0.3917932 , 0.39151853, 0.39144427,\n",
       "        0.38970774, 0.38967282, 0.3886765 , 0.3886527 , 0.3883962 ,\n",
       "        0.38823465, 0.38659307, 0.3865549 , 0.38642195, 0.386279  ,\n",
       "        0.38588384, 0.3858827 , 0.38583508, 0.38563788, 0.38544208,\n",
       "        0.38543952, 0.38531324, 0.3849383 , 0.38493592, 0.3848891 ,\n",
       "        0.38475493, 0.38461277, 0.38460463, 0.3840475 , 0.38389224,\n",
       "        0.38378274, 0.3836637 , 0.38307905, 0.38264632, 0.38232368,\n",
       "        0.38127738, 0.38107052, 0.38087422, 0.38021082, 0.37966502,\n",
       "        0.37830403, 0.3766511 , 0.3752865 , 0.37356904, 0.37217206,\n",
       "        0.3713172 , 0.37116075, 0.36907792, 0.36777475, 0.3674211 ,\n",
       "        0.36421388, 0.36332256, 0.3584461 , 0.33849838, 0.3375501 ,\n",
       "        0.3362462 , 0.33264583, 0.32774097, 0.32677132, 0.32585746,\n",
       "        0.32561392, 0.3234113 , 0.3232556 , 0.32199055, 0.32160842,\n",
       "        0.31784156, 0.31744626, 0.31379333, 0.31240723, 0.3122437 ,\n",
       "        0.31144947, 0.3045873 , 0.30303934, 0.30018443, 0.29993117,\n",
       "        0.29896122, 0.29862374, 0.29837158, 0.29723528, 0.29526013,\n",
       "        0.29515678, 0.29318616, 0.29271436, 0.2867592 , 0.2866165 ,\n",
       "        0.28461406, 0.28386384, 0.27344334, 0.2727132 , 0.27257118,\n",
       "        0.27221134, 0.2571011 , 0.2550903 , 0.23892243, 0.2384102 ,\n",
       "        0.23023358, 0.23016839, 0.22521944], dtype=float32),\n",
       " 'F1 Score': 0.6743697478991597,\n",
       " 'Accuracy': 0.7181818181818181,\n",
       " 'Recall': 0.6056603773584905,\n",
       " 'Precision': 0.7606635071090048,\n",
       " 'Confusion Matrix': array([[469, 101],\n",
       "        [209, 321]], dtype=int64)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular las métricas\n",
    "metrics = clf_metrics(y_true, y_pred, y_prob)\n",
    "\n",
    "# Mostrar los resultados\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0.0 1.0]\n",
      "y_prob range: 0.22521944 0.7881479\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"y_true:\", np.unique(y_true))  # Debería mostrar solo 0 y 1\n",
    "print(\"y_prob range:\", y_prob.min(), y_prob.max())  # Debería estar entre 0 y 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(metrics):\n",
    "    \"\"\"\n",
    "    Función para graficar la curva ROC con FPR, TPR y el AUC en el título.\n",
    "\n",
    "    Parámetros:\n",
    "    - metrics: diccionario que contiene 'FPR', 'TPR' y 'AUC'.\n",
    "    \"\"\"\n",
    "    title='ROC Curve'\n",
    "    title_metrics = f'ROC \\nacc={metrics['Accuracy']:.2f}  prec={metrics['Precision']:.2f}  f1={metrics['F1 Score']:.2f}  rec={metrics['Recall']:.2f}'\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.plot(metrics['FPR'], metrics['TPR'], color='darkorange', lw=2, label=f'ROC curve (AUC = {metrics[\"AUC\"]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')  # Línea diagonal de referencia\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title(title_metrics)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Llamada a la función\n",
    "plot_roc_curve(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sex': 103.0, 'Educ': 393.0, 'MMSE': 244.0, 'GINI': 646.0, 'Diagnosis': 42.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model['model'][0].get_booster().get_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antiguo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature   F-score   p-value\n",
      "0  feature_1  1.755164  0.188310\n",
      "1  feature_2  0.044922  0.832588\n",
      "2  feature_3  1.354646  0.247293\n",
      "3  feature_4  0.036762  0.848347\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Crear datos inventados\n",
    "np.random.seed(0)  # Fijar la semilla para reproducibilidad\n",
    "n_samples = 100  # Número de muestras\n",
    "\n",
    "# Crear características\n",
    "X = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(0, 1, n_samples),\n",
    "    'feature_2': np.random.normal(1, 2, n_samples),\n",
    "    'feature_3': np.random.normal(-1, 1, n_samples),\n",
    "    'feature_4': np.random.normal(2, 3, n_samples)\n",
    "})\n",
    "\n",
    "# Crear etiquetas de clase (0 o 1)\n",
    "y = np.random.choice([0, 1], size=n_samples)\n",
    "\n",
    "# Calcular F-score y p-valores para cada característica\n",
    "f_scores, p_values = f_classif(X, y)\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "f_score_df = pd.DataFrame({'Feature': X.columns, 'F-score': f_scores, 'p-value': p_values})\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f_score_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_age_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
